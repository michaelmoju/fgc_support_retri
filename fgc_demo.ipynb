{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1125 06:44:28.695613 140462858368832 file_utils.py:39] PyTorch version 1.1.0 available.\n",
      "I1125 06:44:29.029454 140462858368832 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torchvision\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1125 06:44:29.582342 140462858368832 corenlp.py:42] Using an existing server http://140.109.19.191:9000\n",
      "I1125 06:44:30.585761 140462858368832 corenlp.py:118] The server is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "import config\n",
    "from fgc_preprocess import FgcSerDataset, BertIdx\n",
    "from torch.utils.data import DataLoader\n",
    "from sup_model import BertSupSentClassification\n",
    "from transformers import BertModel\n",
    "from transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1125 06:44:31.506117 140462858368832 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing /work/fgc_support_retri/data/FGC/1.2/FGC_release_A_train(cn).json ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaf47ab4a654801b3167ac66c31bae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "D036\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "D040\n",
      "aspan error:  2019 \n",
      "{'QTYPE': '基础题', 'AMODE': 'Multi-Spans-Extraction', 'ASPAN': [{'text': '木雕博馆广场', 'end': 36, 'start': 30}, {'text': '水美商圈', 'end': 41, 'start': 37}, {'text': ' 2019', 'end': 4, 'start': -1}, {'text': '三义木雕艺术节', 'end': 11, 'start': 4}, {'text': '擧行', 'end': 45, 'start': 43}], 'ATYPE': 'Location', 'SHINT': [{'text': '2019三义木雕艺术节系列活动将从10月10日起一连四天，在木雕博馆广场及水美商圈盛大擧行，现场除了国内外的木雕作品展示，还有艺文表演、茶席体验等，民众不妨趁著双十假期到三义感受慢城之美', 'end': 93, 'start': 0}, {'text': ' 记者\\u3000陈怡伶\\u3000报导 2019三义木雕艺术节系列活动以「艺动-木艺慢活嘉年华」为主题，结合三义慢城意象，以及独特木雕与茶文化特色，邀请民众来一趟深度探索之旅，三义木雕博物馆也配合这次活动，自国庆日起连续四天免费开放参观', 'end': 203, 'start': 94}], 'QTEXT': '2019三义木雕艺术节活动于三义的哪两个地点举行?', 'QID': 'D068Q05', 'ANSWER': [{'ATOKEN': [{'text': '木雕博馆广场', 'start': 30}, {'text': '水美商圈', 'start': 37}], 'ATEXT': '木雕博馆广场及水美商圈'}]}\n",
      "\n",
      "data size = 332\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "train_set = FgcSerDataset(config.FGC_TRAIN,\n",
    "                        transform=torchvision.transforms.Compose([BertIdx(tokenizer)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1125 06:46:59.585567 140462858368832 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.0c16faba8be66db3f02805c912e4cf94d3c9cffc1f12fa1a39906f9270f76d33\n",
      "I1125 06:46:59.587941 140462858368832 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I1125 06:47:00.530328 140462858368832 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "bert_model_name = 'bert-base-chinese'\n",
    "warmup_proportion = 0.1\n",
    "learning_rate = 5e-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_num = 0 if torch.cuda.is_available() else -1\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "bert_encoder = BertModel.from_pretrained(bert_model_name)\n",
    "model = BertSupSentClassification(bert_encoder)\n",
    "\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "if n_gpu > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "\n",
    "print('start training ... ')\n",
    "\n",
    "model.train()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5275bceadbb244f4b0bd912cb5f331a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.065\n",
      "[1,    11] loss: 0.558\n",
      "[1,    21] loss: 0.467\n",
      "[1,    31] loss: 0.406\n",
      "[1,    41] loss: 0.316\n",
      "[1,    51] loss: 0.370\n",
      "[1,    61] loss: 0.251\n",
      "[1,    71] loss: 0.396\n",
      "[1,    81] loss: 0.389\n",
      "[1,    91] loss: 0.532\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6624bd4ad947278f1af92f69f66543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/fgc_support_retri/fgc_support_retri/fgc_preprocess.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample['label'] = torch.tensor(sample['label'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.042\n",
      "[2,    11] loss: 0.507\n",
      "[2,    21] loss: 0.371\n",
      "[2,    31] loss: 0.342\n",
      "[2,    41] loss: 0.318\n",
      "[2,    51] loss: 0.344\n",
      "[2,    61] loss: 0.234\n",
      "[2,    71] loss: 0.315\n",
      "[2,    81] loss: 0.340\n",
      "[2,    91] loss: 0.412\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09456016c5334cd880d18f991adee76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,     1] loss: 0.041\n",
      "[3,    11] loss: 0.463\n",
      "[3,    21] loss: 0.336\n",
      "[3,    31] loss: 0.270\n",
      "[3,    41] loss: 0.301\n",
      "[3,    51] loss: 0.350\n",
      "[3,    61] loss: 0.230\n",
      "[3,    71] loss: 0.321\n",
      "[3,    81] loss: 0.339\n",
      "[3,    91] loss: 0.415\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a3f5120f134a69801ab40b3db4b559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,     1] loss: 0.031\n",
      "[4,    11] loss: 0.466\n",
      "[4,    21] loss: 0.333\n",
      "[4,    31] loss: 0.278\n",
      "[4,    41] loss: 0.251\n",
      "[4,    51] loss: 0.299\n",
      "[4,    61] loss: 0.187\n",
      "[4,    71] loss: 0.261\n",
      "[4,    81] loss: 0.279\n",
      "[4,    91] loss: 0.391\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b7dcf19c454a99861ea021cd0bfea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     1] loss: 0.022\n",
      "[5,    11] loss: 0.405\n",
      "[5,    21] loss: 0.318\n",
      "[5,    31] loss: 0.244\n",
      "[5,    41] loss: 0.225\n",
      "[5,    51] loss: 0.284\n",
      "[5,    61] loss: 0.173\n",
      "[5,    71] loss: 0.231\n",
      "[5,    81] loss: 0.251\n",
      "[5,    91] loss: 0.320\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9713723131fb4899958461365fa410c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,     1] loss: 0.040\n",
      "[6,    11] loss: 0.392\n",
      "[6,    21] loss: 0.279\n",
      "[6,    31] loss: 0.241\n",
      "[6,    41] loss: 0.230\n",
      "[6,    51] loss: 0.234\n",
      "[6,    61] loss: 0.185\n",
      "[6,    71] loss: 0.230\n",
      "[6,    81] loss: 0.251\n",
      "[6,    91] loss: 0.267\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134667ab4aad4578a4ae9030739e930d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,     1] loss: 0.023\n",
      "[7,    11] loss: 0.416\n",
      "[7,    21] loss: 0.258\n",
      "[7,    31] loss: 0.235\n",
      "[7,    41] loss: 0.225\n",
      "[7,    51] loss: 0.309\n",
      "[7,    61] loss: 0.201\n",
      "[7,    71] loss: 0.206\n",
      "[7,    81] loss: 0.218\n",
      "[7,    91] loss: 0.285\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29bfcf7d54640b491be74e0c758f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,     1] loss: 0.029\n",
      "[8,    11] loss: 0.497\n",
      "[8,    21] loss: 0.285\n",
      "[8,    31] loss: 0.239\n",
      "[8,    41] loss: 0.223\n",
      "[8,    51] loss: 0.250\n",
      "[8,    61] loss: 0.173\n",
      "[8,    71] loss: 0.229\n",
      "[8,    81] loss: 0.206\n",
      "[8,    91] loss: 0.234\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b115f7fb45d84288acc5e8385398169b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,     1] loss: 0.030\n",
      "[9,    11] loss: 0.360\n",
      "[9,    21] loss: 0.262\n",
      "[9,    31] loss: 0.207\n",
      "[9,    41] loss: 0.198\n",
      "[9,    51] loss: 0.238\n",
      "[9,    61] loss: 0.172\n",
      "[9,    71] loss: 0.210\n",
      "[9,    81] loss: 0.193\n",
      "[9,    91] loss: 0.219\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f341de407745dab96a836dc62d6928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,     1] loss: 0.021\n",
      "[10,    11] loss: 0.348\n",
      "[10,    21] loss: 0.211\n",
      "[10,    31] loss: 0.205\n",
      "[10,    41] loss: 0.200\n",
      "[10,    51] loss: 0.255\n",
      "[10,    61] loss: 0.172\n",
      "[10,    71] loss: 0.225\n",
      "[10,    81] loss: 0.203\n",
      "[10,    91] loss: 0.216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataloader_train = DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "for epoch_i in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_i, batch in enumerate(tqdm(dataloader_train)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model(input_ids, token_type_ids=token_type_ids,\n",
    "                     attention_mask=attention_mask, mode=BertSupSentClassification.ForwardMode.TRAIN,\n",
    "                     labels=labels)\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean()  # mean() to average on multi-gpu.\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_i % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch_i + 1, batch_i + 1, running_loss / 10))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "torch.save(model_to_save.state_dict(), 'trainedmodel.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
