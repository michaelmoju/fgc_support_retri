{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0409 03:07:19.640415 140273518446400 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.dataset_reader.sentence_group_reader import *\n",
    "from fgc_support_retri.dataset_reader.sentence_reader import *\n",
    "from fgc_support_retri import config\n",
    "from fgc_support_retri.utils import json_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "for d_i, d in enumerate(data):\n",
    "    for q in d['QUESTIONS']:\n",
    "        if q['QID'] == 'D049Q03':\n",
    "            print(d_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0409 03:07:21.377386 140273518446400 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0409 03:07:22.326778 140273518446400 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0409 03:07:22.329594 140273518446400 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0409 03:07:23.215267 140273518446400 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_EMBEDDING_ZH)\n",
    "bert = BertModel.from_pretrained(config.BERT_EMBEDDING_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1052.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 837.52it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = SerSentenceDataset([data[54]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D049Q03',\n",
       " 'QTEXT': '「雅婷逐字稿」可以听懂几种语言?',\n",
       " 'sentence': '\\n\\n杜奕瑾今年初接受商业周刊采访时说，',\n",
       " 'other_context': '「PTT创世神」杜奕瑾创办的台湾人工智慧实验室推出「雅婷逐字稿」App，已在iOS与Android平台上线，官方表示能节省至少60%的听打时间，还听得懂台湾国语和中英夹杂。\\n\\n根据App官方介绍，由台湾人工智慧实验室（AILabs）推出的「雅婷逐字稿」App除了能即时做语音转文字，也可以用来提升听障人沟通效率。无论是记录生活大小事，或是记录访谈、课堂、会议内容，都可以精准且快速地达成原本需要花费大量时间才有的逐字稿。\\n\\n脸书帐号Shar Yuan的台湾人工智慧实验室员工日前发文说明，透过「雅婷逐字稿」，听障人士可透过文字的方式理解其他人在说什么，媒体工作者或记者能即时生成访谈或会议逐字稿，老师也能快速生成课程文字档。行政院政务委员唐凤为提倡政府资讯公开，常带著每分钟打字高达350字的速录师薛雅婷为会议制作逐字稿，因此台湾人工智慧实验室把内部开发的语音辨识系统取名为「雅婷一号」。\\n\\n杜奕瑾在访谈中指出，国际大厂已把英文、中文语音辨识的应用做得很好，台商机会在于把本土腔调和特殊用语做得更精进。',\n",
       " 'context_sents': ['「PTT创世神」杜奕瑾创办的台湾人工智慧实验室推出「雅婷逐字稿」App，',\n",
       "  '已在iOS与Android平台上线，',\n",
       "  '官方表示能节省至少60%的听打时间，',\n",
       "  '还听得懂台湾国语和中英夹杂。',\n",
       "  '\\n\\n根据App官方介绍，',\n",
       "  '由台湾人工智慧实验室（AILabs）推出的「雅婷逐字稿」App除了能即时做语音转文字，',\n",
       "  '也可以用来提升听障人沟通效率。',\n",
       "  '无论是记录生活大小事，',\n",
       "  '或是记录访谈、课堂、会议内容，',\n",
       "  '都可以精准且快速地达成原本需要花费大量时间才有的逐字稿。',\n",
       "  '\\n\\n脸书帐号Shar Yuan的台湾人工智慧实验室员工日前发文说明，',\n",
       "  '透过「雅婷逐字稿」，',\n",
       "  '听障人士可透过文字的方式理解其他人在说什么，',\n",
       "  '媒体工作者或记者能即时生成访谈或会议逐字稿，',\n",
       "  '老师也能快速生成课程文字档。',\n",
       "  '行政院政务委员唐凤为提倡政府资讯公开，',\n",
       "  '常带著每分钟打字高达350字的速录师薛雅婷为会议制作逐字稿，',\n",
       "  '因此台湾人工智慧实验室把内部开发的语音辨识系统取名为「雅婷一号」。',\n",
       "  '\\n\\n杜奕瑾在访谈中指出，',\n",
       "  '国际大厂已把英文、中文语音辨识的应用做得很好，',\n",
       "  '台商机会在于把本土腔调和特殊用语做得更精进。'],\n",
       " 'atype': 'Num-Measure',\n",
       " 'q_ne': {1: 'NUMBER'},\n",
       " 'q_piece': ['「雅婷逐字稿」可以听懂', '几', '种语言?'],\n",
       " 's_ne': {1: 'PER', 3: 'DATE'},\n",
       " 's_piece': ['\\n\\n', '杜奕瑾', '', '今年', '初接受商业周刊采访时说，'],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n根据App官方介绍，']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[4]['s_piece']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D049Q03',\n",
       " 'QTEXT': '「雅婷逐字稿」可以听懂几种语言?',\n",
       " 'sentence': '\\n\\n根据App官方介绍，',\n",
       " 'other_context': '「PTT创世神」杜奕瑾创办的台湾人工智慧实验室推出「雅婷逐字稿」App，已在iOS与Android平台上线，官方表示能节省至少60%的听打时间，还听得懂台湾国语和中英夹杂。由台湾人工智慧实验室（AILabs）推出的「雅婷逐字稿」App除了能即时做语音转文字，也可以用来提升听障人沟通效率。无论是记录生活大小事，或是记录访谈、课堂、会议内容，都可以精准且快速地达成原本需要花费大量时间才有的逐字稿。\\n\\n脸书帐号Shar Yuan的台湾人工智慧实验室员工日前发文说明，透过「雅婷逐字稿」，听障人士可透过文字的方式理解其他人在说什么，媒体工作者或记者能即时生成访谈或会议逐字稿，老师也能快速生成课程文字档。\\n\\n杜奕瑾今年初接受商业周刊采访时说，行政院政务委员唐凤为提倡政府资讯公开，常带著每分钟打字高达350字的速录师薛雅婷为会议制作逐字稿，因此台湾人工智慧实验室把内部开发的语音辨识系统取名为「雅婷一号」。\\n\\n杜奕瑾在访谈中指出，国际大厂已把英文、中文语音辨识的应用做得很好，台商机会在于把本土腔调和特殊用语做得更精进。',\n",
       " 'context_sents': ['「PTT创世神」杜奕瑾创办的台湾人工智慧实验室推出「雅婷逐字稿」App，',\n",
       "  '已在iOS与Android平台上线，',\n",
       "  '官方表示能节省至少60%的听打时间，',\n",
       "  '还听得懂台湾国语和中英夹杂。',\n",
       "  '由台湾人工智慧实验室（AILabs）推出的「雅婷逐字稿」App除了能即时做语音转文字，',\n",
       "  '也可以用来提升听障人沟通效率。',\n",
       "  '无论是记录生活大小事，',\n",
       "  '或是记录访谈、课堂、会议内容，',\n",
       "  '都可以精准且快速地达成原本需要花费大量时间才有的逐字稿。',\n",
       "  '\\n\\n脸书帐号Shar Yuan的台湾人工智慧实验室员工日前发文说明，',\n",
       "  '透过「雅婷逐字稿」，',\n",
       "  '听障人士可透过文字的方式理解其他人在说什么，',\n",
       "  '媒体工作者或记者能即时生成访谈或会议逐字稿，',\n",
       "  '老师也能快速生成课程文字档。',\n",
       "  '\\n\\n杜奕瑾今年初接受商业周刊采访时说，',\n",
       "  '行政院政务委员唐凤为提倡政府资讯公开，',\n",
       "  '常带著每分钟打字高达350字的速录师薛雅婷为会议制作逐字稿，',\n",
       "  '因此台湾人工智慧实验室把内部开发的语音辨识系统取名为「雅婷一号」。',\n",
       "  '\\n\\n杜奕瑾在访谈中指出，',\n",
       "  '国际大厂已把英文、中文语音辨识的应用做得很好，',\n",
       "  '台商机会在于把本土腔调和特殊用语做得更精进。'],\n",
       " 'atype': 'Num-Measure',\n",
       " 'q_ne': {1: 'NUMBER'},\n",
       " 'q_piece': ['「雅婷逐字稿」可以听懂', '几', '种语言?'],\n",
       " 's_ne': {},\n",
       " 's_piece': ['\\n\\n根据App官方介绍，'],\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  519,\n",
       "  7414,\n",
       "  2051,\n",
       "  6852,\n",
       "  2099,\n",
       "  4943,\n",
       "  520,\n",
       "  1377,\n",
       "  809,\n",
       "  1420,\n",
       "  2743,\n",
       "  1126,\n",
       "  4905,\n",
       "  6427,\n",
       "  6241,\n",
       "  136,\n",
       "  102,\n",
       "  3418,\n",
       "  2945,\n",
       "  100,\n",
       "  2135,\n",
       "  3175,\n",
       "  792,\n",
       "  5305,\n",
       "  8024,\n",
       "  102],\n",
       " 'question_ids': [101,\n",
       "  519,\n",
       "  7414,\n",
       "  2051,\n",
       "  6852,\n",
       "  2099,\n",
       "  4943,\n",
       "  520,\n",
       "  1377,\n",
       "  809,\n",
       "  1420,\n",
       "  2743,\n",
       "  1126,\n",
       "  4905,\n",
       "  6427,\n",
       "  6241,\n",
       "  136,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'tf_match': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'idf_match': [0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " 'sf_type': [9,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  9,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  9],\n",
       " 'qsim_type': [0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0],\n",
       " 'etype_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  11,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'atype_label': 4,\n",
       " 'atype_ent_match': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'sf_score': [1,\n",
       "  0.8095248095238096,\n",
       "  0.7619057619047619,\n",
       "  0.7619057619047619,\n",
       "  0.7142867142857143,\n",
       "  0.6190486190476191,\n",
       "  0.7142867142857143,\n",
       "  0.8095248095238096,\n",
       "  0.8571438571428572,\n",
       "  0.9047629047619048,\n",
       "  0.8095248095238096,\n",
       "  0.9523819523809524,\n",
       "  1.000001,\n",
       "  1.000001,\n",
       "  0.7619057619047619,\n",
       "  1.000001,\n",
       "  1.000001,\n",
       "  1,\n",
       "  1.000001,\n",
       "  1.000001,\n",
       "  0.8095248095238096,\n",
       "  0.9523819523809524,\n",
       "  0.9047629047619048,\n",
       "  1.000001,\n",
       "  1.000001,\n",
       "  0.28571528571428567,\n",
       "  1],\n",
       " 'amatch_type': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentIdx(tokenizer, bert)(sample[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = SerSGroupDataset(data, transform=torchvision.transforms.Compose([SGroupIdx(tokenizer, bert)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(sample, batch_size=12, shuffle=True, collate_fn=SGroup_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(dataloader_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 96, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['sf_score'].unsqueeze(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0312 04:33:49.814485 139759532590912 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0312 04:33:49.817665 139759532590912 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0312 04:33:50.687346 139759532590912 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 96])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2346,  1.0275,  0.4232,  ...,  0.3071, -0.1894,  0.0218],\n",
       "         [-0.1520,  0.3440,  0.3595,  ..., -0.3183, -0.3259,  0.0587],\n",
       "         [ 0.1665,  0.1313,  0.2115,  ..., -0.1133, -0.2711, -0.2806],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1221,  1.0173,  0.1517,  ...,  0.2913,  0.0085,  0.1280],\n",
       "         [-0.1687,  0.2954,  0.7044,  ..., -0.5417, -0.2595, -0.0528],\n",
       "         [ 0.3971,  0.2900,  0.2430,  ...,  0.1885, -0.4232,  0.0055],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4357,  1.0312,  0.1943,  ...,  0.3674, -0.1535,  0.1093],\n",
       "         [-0.1198,  0.4018,  0.2719,  ..., -0.3908, -0.2624,  0.0582],\n",
       "         [ 0.3997, -0.1245, -0.2792,  ...,  0.2475,  0.1070, -0.3370],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5892,  0.7424,  0.1929,  ...,  0.4418, -0.0915, -0.0560],\n",
       "         [-0.0983,  0.2253,  0.5610,  ..., -0.2999, -0.4762, -0.0846],\n",
       "         [-0.1067, -0.6529, -0.6009,  ...,  1.1190,  0.3796,  0.1749],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4523,  0.8541, -0.1701,  ...,  0.5546,  0.3469,  0.1176],\n",
       "         [-0.7619,  0.7176,  0.3981,  ..., -0.6848,  0.1089, -0.1577],\n",
       "         [-0.1593,  0.2174, -0.1460,  ...,  0.7622,  0.6320,  0.2100],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.2830,  0.9127, -0.2130,  ...,  0.8274, -0.0860,  0.3520],\n",
       "         [ 0.1693,  0.1392,  0.4963,  ..., -0.5282, -0.2118, -0.0349],\n",
       "         [ 0.3729,  0.1978, -0.1095,  ...,  0.4436, -0.0792,  0.4272],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(emb[0], batch['sf_score'].unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
