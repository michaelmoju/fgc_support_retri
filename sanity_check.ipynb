{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/moju/data/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_reader.sentence_reader import *\n",
    "import config\n",
    "from utils import read_fgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "no gold supporting evidence\n",
      "{'QID': 'D001Q11', 'QTYPE': '申論', 'ATYPE': 'Event', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '蘇東坡為何被後人認為是文學藝術史上的通才?', 'QTEXT_CN': '苏东坡为何被后人认为是文学艺术史上的通才?', 'SENTS': [{'text': '苏东坡为何被后人认为是文学艺术史上的通才?', 'start': 0, 'end': 21}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '苏东坡', 'type': 'PER', 'char_b': 0, 'char_e': 3}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '苏东坡', 'char_b': 0, 'char_e': 3, 'pos': 'NR'}, {'word': '为何', 'char_b': 3, 'char_e': 5, 'pos': 'AD'}, {'word': '被', 'char_b': 5, 'char_e': 6, 'pos': 'LB'}, {'word': '后人', 'char_b': 6, 'char_e': 8, 'pos': 'NN'}, {'word': '认为', 'char_b': 8, 'char_e': 10, 'pos': 'VV'}, {'word': '是', 'char_b': 10, 'char_e': 11, 'pos': 'VC'}, {'word': '文学', 'char_b': 11, 'char_e': 13, 'pos': 'NN'}, {'word': '艺术史', 'char_b': 13, 'char_e': 16, 'pos': 'NN'}, {'word': '上', 'char_b': 16, 'char_e': 17, 'pos': 'LC'}, {'word': '的', 'char_b': 17, 'char_e': 18, 'pos': 'DEG'}, {'word': '通才', 'char_b': 18, 'char_e': 20, 'pos': 'NN'}, {'word': '?', 'char_b': 20, 'char_e': 21, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申論', 'ATYPE': 'Event', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '雅婷逐字稿', 'type': 'MISC', 'char_b': 1, 'char_e': 6}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '「', 'char_b': 0, 'char_e': 1, 'pos': 'PU'}, {'word': '雅婷', 'char_b': 1, 'char_e': 3, 'pos': 'NR'}, {'word': '逐字稿', 'char_b': 3, 'char_e': 6, 'pos': 'NN'}, {'word': '」', 'char_b': 6, 'char_e': 7, 'pos': 'PU'}, {'word': '的', 'char_b': 7, 'char_e': 8, 'pos': 'DEG'}, {'word': '命名', 'char_b': 8, 'char_e': 10, 'pos': 'NN'}, {'word': '起源', 'char_b': 10, 'char_e': 12, 'pos': 'NN'}, {'word': '为何', 'char_b': 12, 'char_e': 14, 'pos': 'AD'}, {'word': '?', 'char_b': 14, 'char_e': 15, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D073Q12', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '台灣對於鯨鯊保育做了哪些努力?', 'QTEXT_CN': '台湾对于鲸鲨保育做了哪些努力?', 'SENTS': [{'text': '台湾对于鲸鲨保育做了哪些努力?', 'start': 0, 'end': 15}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '台湾', 'type': 'GPE', 'char_b': 0, 'char_e': 2}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '台湾', 'char_b': 0, 'char_e': 2, 'pos': 'NR'}, {'word': '对于', 'char_b': 2, 'char_e': 4, 'pos': 'P'}, {'word': '鲸鲨', 'char_b': 4, 'char_e': 6, 'pos': 'NN'}, {'word': '保育', 'char_b': 6, 'char_e': 8, 'pos': 'NN'}, {'word': '做了', 'char_b': 8, 'char_e': 10, 'pos': 'VV'}, {'word': '哪些', 'char_b': 10, 'char_e': 12, 'pos': 'DT'}, {'word': '努力', 'char_b': 12, 'char_e': 14, 'pos': 'NN'}, {'word': '?', 'char_b': 14, 'char_e': 15, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q08', 'QTYPE': '進階題', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '妻子的叔叔要怎麼叫他?', 'QTEXT_CN': '妻子的叔叔要怎么叫他?', 'SENTS': [{'text': '妻子的叔叔要怎么叫他?', 'start': 0, 'end': 11}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '妻子', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '的', 'char_b': 2, 'char_e': 3, 'pos': 'DEG'}, {'word': '叔叔', 'char_b': 3, 'char_e': 5, 'pos': 'NN'}, {'word': '要', 'char_b': 5, 'char_e': 6, 'pos': 'VV'}, {'word': '怎么', 'char_b': 6, 'char_e': 8, 'pos': 'AD'}, {'word': '叫', 'char_b': 8, 'char_e': 9, 'pos': 'VV'}, {'word': '他', 'char_b': 9, 'char_e': 10, 'pos': 'PN'}, {'word': '?', 'char_b': 10, 'char_e': 11, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATEXT_CN': '资讯不足无法判定', 'ATOKEN': [{'text': '資訊不足無法判定', 'text_cn': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q09', 'QTYPE': '進階題', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '妻子的叔叔要怎麼稱呼他?', 'QTEXT_CN': '妻子的叔叔要怎么称呼他?', 'SENTS': [{'text': '妻子的叔叔要怎么称呼他?', 'start': 0, 'end': 12}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '妻子', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '的', 'char_b': 2, 'char_e': 3, 'pos': 'DEG'}, {'word': '叔叔', 'char_b': 3, 'char_e': 5, 'pos': 'NN'}, {'word': '要', 'char_b': 5, 'char_e': 6, 'pos': 'VV'}, {'word': '怎么', 'char_b': 6, 'char_e': 8, 'pos': 'AD'}, {'word': '称呼', 'char_b': 8, 'char_e': 10, 'pos': 'VV'}, {'word': '他', 'char_b': 10, 'char_e': 11, 'pos': 'PN'}, {'word': '?', 'char_b': 11, 'char_e': 12, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATEXT_CN': '资讯不足无法判定', 'ATOKEN': [{'text': '資訊不足無法判定', 'text_cn': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q10', 'QTYPE': '進階題', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '妻子的嬸嬸要怎麼叫她?', 'QTEXT_CN': '妻子的婶婶要怎么叫她?', 'SENTS': [{'text': '妻子的婶婶要怎么叫她?', 'start': 0, 'end': 11}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '妻子', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '的', 'char_b': 2, 'char_e': 3, 'pos': 'DEG'}, {'word': '婶婶', 'char_b': 3, 'char_e': 5, 'pos': 'NN'}, {'word': '要', 'char_b': 5, 'char_e': 6, 'pos': 'VV'}, {'word': '怎么', 'char_b': 6, 'char_e': 8, 'pos': 'AD'}, {'word': '叫', 'char_b': 8, 'char_e': 9, 'pos': 'VV'}, {'word': '她', 'char_b': 9, 'char_e': 10, 'pos': 'PN'}, {'word': '?', 'char_b': 10, 'char_e': 11, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATEXT_CN': '资讯不足无法判定', 'ATOKEN': [{'text': '資訊不足無法判定', 'text_cn': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D103Q07', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '什麼是「325停課標準」?', 'QTEXT_CN': '什么是「325停课标准」?', 'SENTS': [{'text': '什么是「325停课标准」?', 'start': 0, 'end': 13}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '325', 'type': 'NUMBER', 'char_b': 4, 'char_e': 7}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '什么', 'char_b': 0, 'char_e': 2, 'pos': 'PN'}, {'word': '是', 'char_b': 2, 'char_e': 3, 'pos': 'VC'}, {'word': '「', 'char_b': 3, 'char_e': 4, 'pos': 'PU'}, {'word': '325', 'char_b': 4, 'char_e': 7, 'pos': 'CD'}, {'word': '停课', 'char_b': 7, 'char_e': 9, 'pos': 'VV'}, {'word': '标准', 'char_b': 9, 'char_e': 11, 'pos': 'NN'}, {'word': '」', 'char_b': 11, 'char_e': 12, 'pos': 'PU'}, {'word': '?', 'char_b': 12, 'char_e': 13, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D289Q07', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '人類藉由普羅米修斯認識了火，發現它不但會發熱發光，還可以做哪些事？', 'QTEXT_CN': '人类借由普罗米修斯认识了火，发现它不但会发热发光，还可以做哪些事？', 'SENTS': [{'text': '人类借由普罗米修斯认识了火，', 'start': 0, 'end': 14}, {'text': '发现它不但会发热发光，', 'start': 14, 'end': 25}, {'text': '还可以做哪些事？', 'start': 25, 'end': 33}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '人类', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '借由', 'char_b': 2, 'char_e': 4, 'pos': 'P'}, {'word': '普罗米修斯', 'char_b': 4, 'char_e': 9, 'pos': 'NR'}, {'word': '认识', 'char_b': 9, 'char_e': 11, 'pos': 'VV'}, {'word': '了', 'char_b': 11, 'char_e': 12, 'pos': 'AS'}, {'word': '火', 'char_b': 12, 'char_e': 13, 'pos': 'NN'}, {'word': '，', 'char_b': 13, 'char_e': 14, 'pos': 'PU'}, {'word': '发现', 'char_b': 14, 'char_e': 16, 'pos': 'VV'}, {'word': '它', 'char_b': 16, 'char_e': 17, 'pos': 'PN'}, {'word': '不但', 'char_b': 17, 'char_e': 19, 'pos': 'AD'}, {'word': '会', 'char_b': 19, 'char_e': 20, 'pos': 'VV'}, {'word': '发热', 'char_b': 20, 'char_e': 22, 'pos': 'VV'}, {'word': '发光', 'char_b': 22, 'char_e': 24, 'pos': 'VV'}, {'word': '，', 'char_b': 24, 'char_e': 25, 'pos': 'PU'}, {'word': '还', 'char_b': 25, 'char_e': 26, 'pos': 'AD'}, {'word': '可以', 'char_b': 26, 'char_e': 28, 'pos': 'VV'}, {'word': '做', 'char_b': 28, 'char_e': 29, 'pos': 'VV'}, {'word': '哪些', 'char_b': 29, 'char_e': 31, 'pos': 'DT'}, {'word': '事', 'char_b': 31, 'char_e': 32, 'pos': 'NN'}, {'word': '？', 'char_b': 32, 'char_e': 33, 'pos': 'PU'}]}, 'SHINT': []}\n"
     ]
    }
   ],
   "source": [
    "data = read_fgc(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D001Q01',\n",
       " 'SENTS': [{'text': '苏轼（1037年1月8日－1101年8月24日），', 'start': 0, 'end': 25},\n",
       "  {'text': '眉州眉山（今四川省眉山市）人，', 'start': 25, 'end': 40},\n",
       "  {'text': '北宋时著名的文学家、政治家、艺术家、医学家。', 'start': 40, 'end': 62},\n",
       "  {'text': '字子瞻，一字和仲，', 'start': 62, 'end': 71},\n",
       "  {'text': '号东坡居士、铁冠道人。', 'start': 71, 'end': 82},\n",
       "  {'text': '嘉佑二年进士，', 'start': 82, 'end': 89},\n",
       "  {'text': '累官至端明殿学士兼翰林学士，', 'start': 89, 'end': 103},\n",
       "  {'text': '礼部尚书。南宋理学方炽时，', 'start': 103, 'end': 116},\n",
       "  {'text': '加赐谥号文忠，', 'start': 116, 'end': 123},\n",
       "  {'text': '复追赠太师。', 'start': 123, 'end': 129},\n",
       "  {'text': '有《东坡先生大全集》及《东坡乐府》词集传世，', 'start': 129, 'end': 151},\n",
       "  {'text': '宋人王宗稷收其作品，', 'start': 151, 'end': 161},\n",
       "  {'text': '编有《苏文忠公全集》。', 'start': 161, 'end': 172},\n",
       "  {'text': '\\n其散文、诗、词、赋均有成就，', 'start': 172, 'end': 187},\n",
       "  {'text': '且善书法和绘画，', 'start': 187, 'end': 195},\n",
       "  {'text': '是文学艺术史上的通才，', 'start': 195, 'end': 206},\n",
       "  {'text': '也是公认韵文散文造诣皆比较杰出的大家。', 'start': 206, 'end': 225},\n",
       "  {'text': '苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，', 'start': 225, 'end': 249},\n",
       "  {'text': '与唐代的古文运动发起者韩愈并称为「韩潮苏海」，', 'start': 249, 'end': 272},\n",
       "  {'text': '也与欧阳修并称「欧苏」；', 'start': 272, 'end': 284},\n",
       "  {'text': '更与父亲苏洵、弟苏辙合称「三苏」，', 'start': 284, 'end': 301},\n",
       "  {'text': '父子三人，同列唐宋八大家。', 'start': 301, 'end': 314},\n",
       "  {'text': '苏轼之诗与黄庭坚并称「苏黄」，', 'start': 314, 'end': 329},\n",
       "  {'text': '又与陆游并称「苏陆」；', 'start': 329, 'end': 340},\n",
       "  {'text': '其词「以诗入词」，', 'start': 340, 'end': 349},\n",
       "  {'text': '首开词坛「豪放」一派，', 'start': 349, 'end': 360},\n",
       "  {'text': '振作了晚唐、五代以来绮靡的西昆体余风。', 'start': 360, 'end': 379},\n",
       "  {'text': '后世与南宋辛弃疾并称「苏辛」，', 'start': 379, 'end': 394},\n",
       "  {'text': '惟苏轼故作豪放，', 'start': 394, 'end': 402},\n",
       "  {'text': '其实清朗；其赋亦颇有名气，', 'start': 402, 'end': 415},\n",
       "  {'text': '最知名者为贬谪期间借题发挥写的前后《赤壁赋》。', 'start': 415, 'end': 438},\n",
       "  {'text': '宋代每逢科考常出现其文命题之考试，', 'start': 438, 'end': 455},\n",
       "  {'text': '故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。', 'start': 455, 'end': 480},\n",
       "  {'text': '艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；', 'start': 480, 'end': 513},\n",
       "  {'text': '其画则开创了湖州画派；', 'start': 513, 'end': 524},\n",
       "  {'text': '并在题画文学史上占有举足轻重的地位。', 'start': 524, 'end': 542}],\n",
       " 'Q_NER': [{'id': 'D0-S0-M0',\n",
       "   'string': '苏东坡',\n",
       "   'type': 'PER',\n",
       "   'char_b': 0,\n",
       "   'char_e': 3},\n",
       "  {'id': 'D0-S0-M1', 'string': '中国', 'type': 'GPE', 'char_b': 4, 'char_e': 6},\n",
       "  {'id': 'D0-S0-M2',\n",
       "   'string': '一',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 12,\n",
       "   'char_e': 13}],\n",
       " 'D_NER': [{'id': 'D0-S0-M0',\n",
       "   'string': '苏轼',\n",
       "   'type': 'PER',\n",
       "   'char_b': 0,\n",
       "   'char_e': 2},\n",
       "  {'id': 'D0-S0-M1',\n",
       "   'string': '1037年1月8日',\n",
       "   'type': 'DATE',\n",
       "   'char_b': 3,\n",
       "   'char_e': 12},\n",
       "  {'id': 'D0-S0-M2',\n",
       "   'string': '－',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 12,\n",
       "   'char_e': 13},\n",
       "  {'id': 'D0-S0-M3',\n",
       "   'string': '1101年8月24日',\n",
       "   'type': 'DATE',\n",
       "   'char_b': 13,\n",
       "   'char_e': 23},\n",
       "  {'id': 'D0-S0-M4',\n",
       "   'string': '今',\n",
       "   'type': 'DATE',\n",
       "   'char_b': 30,\n",
       "   'char_e': 31},\n",
       "  {'id': 'D0-S0-M5',\n",
       "   'string': '四川省',\n",
       "   'type': 'GPE',\n",
       "   'char_b': 31,\n",
       "   'char_e': 34},\n",
       "  {'id': 'D0-S0-M6',\n",
       "   'string': '眉山市',\n",
       "   'type': 'GPE',\n",
       "   'char_b': 34,\n",
       "   'char_e': 37},\n",
       "  {'id': 'D0-S0-M7',\n",
       "   'string': '北宋',\n",
       "   'type': 'GPE',\n",
       "   'char_b': 40,\n",
       "   'char_e': 42},\n",
       "  {'id': 'D0-S0-M8',\n",
       "   'string': '文学家',\n",
       "   'type': 'TITLE',\n",
       "   'char_b': 46,\n",
       "   'char_e': 49},\n",
       "  {'id': 'D0-S0-M9',\n",
       "   'string': '艺术家',\n",
       "   'type': 'TITLE',\n",
       "   'char_b': 54,\n",
       "   'char_e': 57},\n",
       "  {'id': 'D0-S0-M10',\n",
       "   'string': '医学家',\n",
       "   'type': 'TITLE',\n",
       "   'char_b': 58,\n",
       "   'char_e': 61},\n",
       "  {'id': 'D0-S1-M0',\n",
       "   'string': '一',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 66,\n",
       "   'char_e': 67},\n",
       "  {'id': 'D0-S2-M0',\n",
       "   'string': '二',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 84,\n",
       "   'char_e': 85},\n",
       "  {'id': 'D0-S2-M1',\n",
       "   'string': '年',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 85,\n",
       "   'char_e': 86},\n",
       "  {'id': 'D0-S4-M0',\n",
       "   'string': '东坡先生大全集',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 131,\n",
       "   'char_e': 138},\n",
       "  {'id': 'D0-S4-M1',\n",
       "   'string': '东坡乐府',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 141,\n",
       "   'char_e': 145},\n",
       "  {'id': 'D0-S4-M2',\n",
       "   'string': '王宗稷',\n",
       "   'type': 'PER',\n",
       "   'char_b': 153,\n",
       "   'char_e': 156},\n",
       "  {'id': 'D0-S4-M3',\n",
       "   'string': '苏文忠公全集',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 164,\n",
       "   'char_e': 170},\n",
       "  {'id': 'D0-S6-M0',\n",
       "   'string': '四',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 232,\n",
       "   'char_e': 233},\n",
       "  {'id': 'D0-S6-M1',\n",
       "   'string': '韩愈',\n",
       "   'type': 'PER',\n",
       "   'char_b': 235,\n",
       "   'char_e': 237},\n",
       "  {'id': 'D0-S6-M2',\n",
       "   'string': '柳宗元',\n",
       "   'type': 'PER',\n",
       "   'char_b': 238,\n",
       "   'char_e': 241},\n",
       "  {'id': 'D0-S6-M3',\n",
       "   'string': '欧苏',\n",
       "   'type': 'PER',\n",
       "   'char_b': 242,\n",
       "   'char_e': 244},\n",
       "  {'id': 'D0-S6-M4',\n",
       "   'string': '韩愈',\n",
       "   'type': 'PER',\n",
       "   'char_b': 259,\n",
       "   'char_e': 261},\n",
       "  {'id': 'D0-S6-M5',\n",
       "   'string': '韩潮苏海',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 265,\n",
       "   'char_e': 269},\n",
       "  {'id': 'D0-S6-M6',\n",
       "   'string': '欧阳修',\n",
       "   'type': 'PER',\n",
       "   'char_b': 273,\n",
       "   'char_e': 276},\n",
       "  {'id': 'D0-S6-M7',\n",
       "   'string': '欧苏',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 279,\n",
       "   'char_e': 281},\n",
       "  {'id': 'D0-S6-M8',\n",
       "   'string': '苏洵',\n",
       "   'type': 'PER',\n",
       "   'char_b': 287,\n",
       "   'char_e': 289},\n",
       "  {'id': 'D0-S6-M9',\n",
       "   'string': '苏辙',\n",
       "   'type': 'PER',\n",
       "   'char_b': 291,\n",
       "   'char_e': 293},\n",
       "  {'id': 'D0-S6-M10',\n",
       "   'string': '三',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 296,\n",
       "   'char_e': 297},\n",
       "  {'id': 'D0-S6-M11',\n",
       "   'string': '苏',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 297,\n",
       "   'char_e': 298},\n",
       "  {'id': 'D0-S6-M12',\n",
       "   'string': '三',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 302,\n",
       "   'char_e': 303},\n",
       "  {'id': 'D0-S6-M13',\n",
       "   'string': '八',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 309,\n",
       "   'char_e': 310},\n",
       "  {'id': 'D0-S7-M0',\n",
       "   'string': '黄庭坚',\n",
       "   'type': 'PER',\n",
       "   'char_b': 318,\n",
       "   'char_e': 321},\n",
       "  {'id': 'D0-S7-M1',\n",
       "   'string': '一',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 356,\n",
       "   'char_e': 357},\n",
       "  {'id': 'D0-S7-M2',\n",
       "   'string': '五代',\n",
       "   'type': 'TIME',\n",
       "   'char_b': 365,\n",
       "   'char_e': 367},\n",
       "  {'id': 'D0-S8-M0',\n",
       "   'string': '辛弃疾',\n",
       "   'type': 'PER',\n",
       "   'char_b': 383,\n",
       "   'char_e': 386},\n",
       "  {'id': 'D0-S8-M1',\n",
       "   'string': '赤壁赋',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 432,\n",
       "   'char_e': 435},\n",
       "  {'id': 'D0-S9-M0',\n",
       "   'string': '当时',\n",
       "   'type': 'DATE',\n",
       "   'char_b': 455,\n",
       "   'char_e': 457},\n",
       "  {'id': 'D0-S9-M1',\n",
       "   'string': '学者',\n",
       "   'type': 'TITLE',\n",
       "   'char_b': 457,\n",
       "   'char_e': 459},\n",
       "  {'id': 'D0-S9-M2',\n",
       "   'string': '苏文生',\n",
       "   'type': 'PER',\n",
       "   'char_b': 470,\n",
       "   'char_e': 473},\n",
       "  {'id': 'D0-S10-M0',\n",
       "   'string': '苏',\n",
       "   'type': 'GPE',\n",
       "   'char_b': 489,\n",
       "   'char_e': 490},\n",
       "  {'id': 'D0-S10-M1',\n",
       "   'string': '黄',\n",
       "   'type': 'PER',\n",
       "   'char_b': 491,\n",
       "   'char_e': 492},\n",
       "  {'id': 'D0-S10-M2',\n",
       "   'string': '蔡',\n",
       "   'type': 'PER',\n",
       "   'char_b': 495,\n",
       "   'char_e': 496},\n",
       "  {'id': 'D0-S10-M3',\n",
       "   'string': '北宋',\n",
       "   'type': 'PER',\n",
       "   'char_b': 497,\n",
       "   'char_e': 499},\n",
       "  {'id': 'D0-S10-M4',\n",
       "   'string': '四',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 499,\n",
       "   'char_e': 500},\n",
       "  {'id': 'D0-S10-M5',\n",
       "   'string': '书法家',\n",
       "   'type': 'TITLE',\n",
       "   'char_b': 501,\n",
       "   'char_e': 504},\n",
       "  {'id': 'D0-S10-M6',\n",
       "   'string': '宋',\n",
       "   'type': 'MISC',\n",
       "   'char_b': 505,\n",
       "   'char_e': 506},\n",
       "  {'id': 'D0-S10-M7',\n",
       "   'string': '四',\n",
       "   'type': 'NUMBER',\n",
       "   'char_b': 506,\n",
       "   'char_e': 507},\n",
       "  {'id': 'D0-S10-M8',\n",
       "   'string': '湖州',\n",
       "   'type': 'GPE',\n",
       "   'char_b': 518,\n",
       "   'char_e': 520}],\n",
       " 'SUP_EVIDENCE': [0, 1, 2, 4],\n",
       " 'QTEXT': '苏东坡在中国历史上，是哪一个朝代的人？',\n",
       " 'ANS': '北宋',\n",
       " 'ATYPE': 'Date-Duration'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_EMBEDDING_ZH)\n",
    "bert = BertModel.from_pretrained(config.BERT_EMBEDDING_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，\n",
      "宋\n",
      "{'char_b': 7, 'char_e': 8, 'string': '四', 'type': 'NUMBER'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-71bec18f4ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerSentenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/moju/data/work/fgc_support_retri/fgc_support_retri/dataset_reader/sentence_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, transform)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/moju/data/work/fgc_support_retri/fgc_support_retri/dataset_reader/sentence_reader.py\u001b[0m in \u001b[0;36mget_sentence_pair\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mtarget_ne_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0ms_ne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_string_pieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerSentenceDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ne_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mother_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/moju/data/work/fgc_support_retri/fgc_support_retri/dataset_reader/sentence_reader.py\u001b[0m in \u001b[0;36mget_ne\u001b[0;34m(ner_list, input_string)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0minput_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_e\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'string'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mstring_pieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mstring_pieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample = SerSentenceDataset(data, transform=torchvision.transforms.Compose([Idx(tokenizer, bert)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D004Q01',\n",
       " 'QTEXT': '蘇東坡在宋哲宗時期,曾出任過哪些官職?',\n",
       " 'sentence': '元祐元年（1086年），',\n",
       " 'other_context': '宋哲宗即位，高太皇太后垂帘听政，回朝任礼部郎中、中书舍人、翰林学士，元祐四年（1089年）拜龙图阁学士，曾出任杭州、颍州等知州职务，官至礼部尚书。\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。\\n元符三年（1100年），宋徽宗即位，向太后垂帘听政，下诏让苏轼北还。\\n建中靖国元年（1101年），夏天因冷饮过度，下痢不止，又误服黄芪，结果病情恶化，「齿间出血如蚯蚓者无数」，七月二十八日于常州孙氏馆病卒，享年六十四岁。由弟苏辙归葬于郏县小峨眉山。南宋宋孝宗追赠谥号「文忠」。\\n苏轼疲于应付新旧党争，遇事「如食内有蝇，吐之乃已」，苏轼既反对王安石比较急进的改革措施，也不同意旧党司马光尽废新法，所以虽然新党一直称苏轼为旧党，但其实他在新旧两党之间均受排斥，仕途坎坷，时常远贬外方，不过他在各地居官清正，为民兴利除弊，政绩颇善，口碑甚佳，杭州西湖的苏堤就是实证。',\n",
       " 'context_sents': ['宋哲宗即位，',\n",
       "  '高太皇太后垂帘听政，',\n",
       "  '回朝任礼部郎中、中书舍人、翰林学士，',\n",
       "  '元祐四年（1089年）拜龙图阁学士，',\n",
       "  '曾出任杭州、颍州等知州职务，',\n",
       "  '官至礼部尚书。',\n",
       "  '\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。',\n",
       "  '\\n元符三年（1100年），',\n",
       "  '宋徽宗即位，',\n",
       "  '向太后垂帘听政，',\n",
       "  '下诏让苏轼北还。',\n",
       "  '\\n建中靖国元年（1101年），',\n",
       "  '夏天因冷饮过度，',\n",
       "  '下痢不止，又误服黄芪，',\n",
       "  '结果病情恶化，',\n",
       "  '「齿间出血如蚯蚓者无数」，',\n",
       "  '七月二十八日于常州孙氏馆病卒，',\n",
       "  '享年六十四岁。',\n",
       "  '由弟苏辙归葬于郏县小峨眉山。',\n",
       "  '南宋宋孝宗追赠谥号「文忠」。',\n",
       "  '\\n苏轼疲于应付新旧党争，',\n",
       "  '遇事「如食内有蝇，吐之乃已」，',\n",
       "  '苏轼既反对王安石比较急进的改革措施，',\n",
       "  '也不同意旧党司马光尽废新法，',\n",
       "  '所以虽然新党一直称苏轼为旧党，',\n",
       "  '但其实他在新旧两党之间均受排斥，',\n",
       "  '仕途坎坷，时常远贬外方，',\n",
       "  '不过他在各地居官清正，',\n",
       "  '为民兴利除弊，',\n",
       "  '政绩颇善，口碑甚佳，',\n",
       "  '杭州西湖的苏堤就是实证。'],\n",
       " 'atype': 'Organization',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  5979,\n",
       "  3346,\n",
       "  1786,\n",
       "  1762,\n",
       "  2129,\n",
       "  1528,\n",
       "  2134,\n",
       "  3229,\n",
       "  3309,\n",
       "  117,\n",
       "  3295,\n",
       "  1139,\n",
       "  818,\n",
       "  6882,\n",
       "  1525,\n",
       "  763,\n",
       "  2135,\n",
       "  5480,\n",
       "  136,\n",
       "  102,\n",
       "  1039,\n",
       "  4860,\n",
       "  1039,\n",
       "  2399,\n",
       "  8020,\n",
       "  8692,\n",
       "  8158,\n",
       "  2399,\n",
       "  8021,\n",
       "  8024,\n",
       "  102],\n",
       " 'question_ids': [101,\n",
       "  5979,\n",
       "  3346,\n",
       "  1786,\n",
       "  1762,\n",
       "  2129,\n",
       "  1528,\n",
       "  2134,\n",
       "  3229,\n",
       "  3309,\n",
       "  117,\n",
       "  3295,\n",
       "  1139,\n",
       "  818,\n",
       "  6882,\n",
       "  1525,\n",
       "  763,\n",
       "  2135,\n",
       "  5480,\n",
       "  136,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'tf_match': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'idf_match': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0],\n",
       " 'sf_type': [19,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  19,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  15,\n",
       "  19],\n",
       " 'qsim_type': [0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  6,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  6,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  2,\n",
       "  7,\n",
       "  0],\n",
       " 'atype_label': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(sample, batch_size=2, shuffle=True, collate_fn=Syn_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7370,   749,  3966,  1990,   809,  1912,  6917,  3300,  6306,\n",
       "           4680,  3080,   749,  1043,  3669,  3428,  8043,   102,  3739,  1990,\n",
       "           1325,  7372,  6381,  7027,  3297,  5543,  6134,  4385,  3739,  1990,\n",
       "           1235,  3140,   510,  3322,  3255,   510,   707,  1314,   679,   744,\n",
       "           4638,   117,  3221,  1091,   800,  1469,  5903,  2010,  1762,  2255,\n",
       "           3822,  7027,  6837,  6662,  4638,  6929,   671,  4995,   511,   102],\n",
       "         [  101,   704,  6956,  3585,  6518,  1062,  6662,  1059,  7269, 12687,\n",
       "           1062,  7027,  8024,  3221,  1415,  3784,  6854,  1392,  1765,  5774,\n",
       "           3893,  6514,  4603,  8043,   102,  7270,  3217,  4870,  4638,  4635,\n",
       "           5298,  3566,  7607,  8024,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'question_ids': tensor([[  101,  7370,   749,  3966,  1990,   809,  1912,  6917,  3300,  6306,\n",
       "           4680,  3080,   749,  1043,  3669,  3428,  8043,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0],\n",
       "         [  101,   704,  6956,  3585,  6518,  1062,  6662,  1059,  7269, 12687,\n",
       "           1062,  7027,  8024,  3221,  1415,  3784,  6854,  1392,  1765,  5774,\n",
       "           3893,  6514,  4603,  8043,   102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'tf_type': tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'idf_type': tensor([[0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'sf_type': tensor([[19,  0,  8,  0, 14,  0,  0,  0,  5,  0,  0,  0,  8,  0,  0,  0,  0, 19,\n",
       "          14, 14,  2,  3,  1,  3,  2,  2,  0,  1, 14, 14,  2,  2,  2,  0,  0,  2,\n",
       "           0,  0,  6,  0, 16, 17,  8,  0,  8,  6,  2,  2,  4,  0,  1,  3,  0,  2,\n",
       "          16,  3,  8,  0, 17, 19],\n",
       "         [19,  1,  1,  0,  0,  3,  3,  0,  0,  0,  3,  0, 14,  4,  0,  0,  0,  0,\n",
       "           1,  0,  0,  0,  0,  0, 19,  0,  0,  0,  9,  0,  0,  1,  0, 14, 19,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0]]),\n",
       " 'qsim_type': tensor([[ 0,  2,  6, 15,  0,  5,  3,  4,  8,  3,  3,  2,  6,  3,  2,  2,  8,  0,\n",
       "          15,  0,  1,  2,  1,  2,  3,  5,  2,  3, 15,  0,  2,  2,  4,  1,  0,  4,\n",
       "           0,  3,  6,  2,  6,  2,  8,  1,  4,  5,  1,  1,  6,  2,  1,  2,  1,  2,\n",
       "           6,  2,  5,  2,  8,  0],\n",
       "         [ 0,  5,  3, 16,  3,  1,  2,  2, 14,  1,  1,  3,  0,  8,  0,  1,  0,  2,\n",
       "           5,  1,  2,  0,  2,  6,  0, 14,  2,  2, 10,  1,  1, 16,  1,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0]]),\n",
       " 'atype_label': tensor([0, 5]),\n",
       " 'label': tensor([0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(dataloader_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_model.multitask_model import MultiSERModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiSERModel.from_pretrained(config.BERT_EMBEDDING_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_mode('syn-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "['YesNo', 'YesNo']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction, atype = model.predict_fgc(iter(dataloader_train).next())\n",
    "    print(prediction)\n",
    "    print(atype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8905, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(iter(dataloader_train).next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
