{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/moju/data/work'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_reader.sentence_reader import *\n",
    "import config\n",
    "from utils import read_fgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "no gold supporting evidence\n",
      "{'QID': 'D001Q11', 'QTYPE': '申論', 'ATYPE': 'Event', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '蘇東坡為何被後人認為是文學藝術史上的通才?', 'QTEXT_CN': '苏东坡为何被后人认为是文学艺术史上的通才?', 'SENTS': [{'text': '苏东坡为何被后人认为是文学艺术史上的通才?', 'start': 0, 'end': 21}], 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申論', 'ATYPE': 'Event', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D073Q12', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '台灣對於鯨鯊保育做了哪些努力?', 'QTEXT_CN': '台湾对于鲸鲨保育做了哪些努力?', 'SENTS': [{'text': '台湾对于鲸鲨保育做了哪些努力?', 'start': 0, 'end': 15}], 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q08', 'QTYPE': '進階題', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '妻子的叔叔要怎麼叫他?', 'QTEXT_CN': '妻子的叔叔要怎么叫他?', 'SENTS': [{'text': '妻子的叔叔要怎么叫他?', 'start': 0, 'end': 11}], 'SHINT': [], 'ANSWER': [{'ATEXT': '资讯不足无法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q09', 'QTYPE': '進階題', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '妻子的叔叔要怎麼稱呼他?', 'QTEXT_CN': '妻子的叔叔要怎么称呼他?', 'SENTS': [{'text': '妻子的叔叔要怎么称呼他?', 'start': 0, 'end': 12}], 'SHINT': [], 'ANSWER': [{'ATEXT': '资讯不足无法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q10', 'QTYPE': '進階題', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '妻子的嬸嬸要怎麼叫她?', 'QTEXT_CN': '妻子的婶婶要怎么叫她?', 'SENTS': [{'text': '妻子的婶婶要怎么叫她?', 'start': 0, 'end': 11}], 'SHINT': [], 'ANSWER': [{'ATEXT': '资讯不足无法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D103Q07', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '什麼是「325停課標準」?', 'QTEXT_CN': '什么是「325停课标准」?', 'SENTS': [{'text': '什么是「325停课标准」?', 'start': 0, 'end': 13}], 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D289Q07', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '人類藉由普羅米修斯認識了火，發現它不但會發熱發光，還可以做哪些事？', 'QTEXT_CN': '人类借由普罗米修斯认识了火，发现它不但会发热发光，还可以做哪些事？', 'SENTS': [{'text': '人类借由普罗米修斯认识了火，', 'start': 0, 'end': 14}, {'text': '发现它不但会发热发光，', 'start': 14, 'end': 25}, {'text': '还可以做哪些事？', 'start': 25, 'end': 33}], 'SHINT': []}\n"
     ]
    }
   ],
   "source": [
    "data = read_fgc(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_EMBEDDING_ZH)\n",
    "bert = BertModel.from_pretrained(config.BERT_EMBEDDING_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = SerSentenceDataset(data, transform=torchvision.transforms.Compose([SynIdx(tokenizer, bert)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D001Q01',\n",
       " 'QTEXT': '蘇東坡在中國歷史上，是哪一個朝代的人？',\n",
       " 'sentence': '苏轼（1037年1月8日－1101年8月24日），',\n",
       " 'other_context': '眉州眉山（今四川省眉山市）人，北宋时著名的文学家、政治家、艺术家、医学家。字子瞻，一字和仲，号东坡居士、铁冠道人。嘉佑二年进士，累官至端明殿学士兼翰林学士，礼部尚书。南宋理学方炽时，加赐谥号文忠，复追赠太师。有《东坡先生大全集》及《东坡乐府》词集传世，宋人王宗稷收其作品，编有《苏文忠公全集》。\\n其散文、诗、词、赋均有成就，且善书法和绘画，是文学艺术史上的通才，也是公认韵文散文造诣皆比较杰出的大家。苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，与唐代的古文运动发起者韩愈并称为「韩潮苏海」，也与欧阳修并称「欧苏」；更与父亲苏洵、弟苏辙合称「三苏」，父子三人，同列唐宋八大家。苏轼之诗与黄庭坚并称「苏黄」，又与陆游并称「苏陆」；其词「以诗入词」，首开词坛「豪放」一派，振作了晚唐、五代以来绮靡的西昆体余风。后世与南宋辛弃疾并称「苏辛」，惟苏轼故作豪放，其实清朗；其赋亦颇有名气，最知名者为贬谪期间借题发挥写的前后《赤壁赋》。宋代每逢科考常出现其文命题之考试，故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；其画则开创了湖州画派；并在题画文学史上占有举足轻重的地位。',\n",
       " 'context_sents': ['眉州眉山（今四川省眉山市）人，',\n",
       "  '北宋时著名的文学家、政治家、艺术家、医学家。',\n",
       "  '字子瞻，一字和仲，',\n",
       "  '号东坡居士、铁冠道人。',\n",
       "  '嘉佑二年进士，',\n",
       "  '累官至端明殿学士兼翰林学士，',\n",
       "  '礼部尚书。南宋理学方炽时，',\n",
       "  '加赐谥号文忠，',\n",
       "  '复追赠太师。',\n",
       "  '有《东坡先生大全集》及《东坡乐府》词集传世，',\n",
       "  '宋人王宗稷收其作品，',\n",
       "  '编有《苏文忠公全集》。',\n",
       "  '\\n其散文、诗、词、赋均有成就，',\n",
       "  '且善书法和绘画，',\n",
       "  '是文学艺术史上的通才，',\n",
       "  '也是公认韵文散文造诣皆比较杰出的大家。',\n",
       "  '苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，',\n",
       "  '与唐代的古文运动发起者韩愈并称为「韩潮苏海」，',\n",
       "  '也与欧阳修并称「欧苏」；',\n",
       "  '更与父亲苏洵、弟苏辙合称「三苏」，',\n",
       "  '父子三人，同列唐宋八大家。',\n",
       "  '苏轼之诗与黄庭坚并称「苏黄」，',\n",
       "  '又与陆游并称「苏陆」；',\n",
       "  '其词「以诗入词」，',\n",
       "  '首开词坛「豪放」一派，',\n",
       "  '振作了晚唐、五代以来绮靡的西昆体余风。',\n",
       "  '后世与南宋辛弃疾并称「苏辛」，',\n",
       "  '惟苏轼故作豪放，',\n",
       "  '其实清朗；其赋亦颇有名气，',\n",
       "  '最知名者为贬谪期间借题发挥写的前后《赤壁赋》。',\n",
       "  '宋代每逢科考常出现其文命题之考试，',\n",
       "  '故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。',\n",
       "  '艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；',\n",
       "  '其画则开创了湖州画派；',\n",
       "  '并在题画文学史上占有举足轻重的地位。'],\n",
       " 'label': 1,\n",
       " 'input_ids': [101,\n",
       "  5979,\n",
       "  3346,\n",
       "  1786,\n",
       "  1762,\n",
       "  704,\n",
       "  1751,\n",
       "  3644,\n",
       "  1380,\n",
       "  677,\n",
       "  8024,\n",
       "  3221,\n",
       "  1525,\n",
       "  671,\n",
       "  943,\n",
       "  3308,\n",
       "  807,\n",
       "  4638,\n",
       "  782,\n",
       "  8043,\n",
       "  102,\n",
       "  5722,\n",
       "  6769,\n",
       "  8020,\n",
       "  8615,\n",
       "  8161,\n",
       "  2399,\n",
       "  122,\n",
       "  3299,\n",
       "  129,\n",
       "  3189,\n",
       "  8025,\n",
       "  8406,\n",
       "  8148,\n",
       "  2399,\n",
       "  129,\n",
       "  3299,\n",
       "  8125,\n",
       "  3189,\n",
       "  8021,\n",
       "  8024,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'tf_match': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " 'idf_match': [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0],\n",
       " 'sf_type': [19,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  0,\n",
       "  19,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  13,\n",
       "  19],\n",
       " 'qsim_type': [0,\n",
       "  15,\n",
       "  3,\n",
       "  4,\n",
       "  7,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  15,\n",
       "  4,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(sample, batch_size=2, shuffle=True, collate_fn=Syn_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6882, 1343, 1282, 2399, 4634, 4495, 4638, 3749, 3582, 6722, 5241,\n",
       "          4125, 3428,  704, 8024, 3221, 1415, 3749, 6722, 4634, 4495, 4638, 3582,\n",
       "          4372, 1920, 3176, 3582, 6722, 8043,  102, 3418, 2945, 1079, 3124, 6956,\n",
       "          5320, 6369, 8024,  102,    0,    0,    0],\n",
       "         [ 101, 7274, 6722, 1139, 7271, 1184, 6206, 6250, 2533,  976, 1525,  763,\n",
       "          6722, 6739, 3596, 3389,  809, 3938, 2208,  769, 6858,  752, 3125, 4634,\n",
       "          4495,  136,  102, 5307, 2175, 4692, 4802, 6371, 6421, 6756, 6775, 2400,\n",
       "          3187, 6629, 4125, 4307, 1105, 8024,  102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'tf_type': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'idf_type': tensor([[0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "          1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]]),\n",
       " 'sf_type': tensor([[19,  0,  0,  0,  0,  0,  1,  6,  1,  0,  0,  0,  8,  1,  0, 14,  1,  0,\n",
       "           1,  0,  0,  1,  6,  0,  0,  2,  0,  0,  0,  0, 19,  0,  0,  2,  3,  2,\n",
       "           0,  0, 14, 19,  0,  0,  0],\n",
       "         [19,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "           1,  1,  2,  6,  6,  0,  2,  0, 19,  1,  0,  0,  2,  1,  0,  9,  1,  0,\n",
       "           1,  5,  2,  2,  1, 15, 19]]),\n",
       " 'qsim_type': tensor([[ 0,  2,  3,  1,  4,  1,  3, 10,  0,  2,  1,  0,  0,  2,  5,  0,  8,  1,\n",
       "           0,  1,  1,  3, 10,  2,  2,  4,  4,  2,  1,  6,  0,  1,  2,  5,  2,  3,\n",
       "           2,  2,  0,  0,  0,  0,  0],\n",
       "         [ 0,  3, 15,  5,  2,  3,  4,  1,  3,  4,  2,  2, 15, 15,  4,  7,  5,  1,\n",
       "           1,  2,  3,  2,  1,  2,  3,  2,  0,  3,  7,  4,  2,  2,  3, 15, 15,  3,\n",
       "           1,  5,  2,  1,  2,  5,  0]]),\n",
       " 'label': tensor([1, 0])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(dataloader_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
