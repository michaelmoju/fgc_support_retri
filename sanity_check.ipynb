{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0507 02:57:37.945083 140049421739840 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.dataset_reader.sentence_group_reader import *\n",
    "from fgc_support_retri.dataset_reader.sentence_reader import *\n",
    "from fgc_support_retri.dataset_reader.advance_sentence_reader import *\n",
    "from fgc_support_retri import config\n",
    "from fgc_support_retri.utils import json_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "for d_i, d in enumerate(data):\n",
    "    for q in d['QUESTIONS']:\n",
    "        if q['QID'] == 'D049Q03':\n",
    "            print(d_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0507 02:57:39.880578 140049421739840 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0507 02:57:40.772716 140049421739840 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0507 02:57:40.775836 140049421739840 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0507 02:57:41.677713 140049421739840 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_EMBEDDING_ZH)\n",
    "indexer = AdvSentIndexer(tokenizer)\n",
    "pretrained_bert = BertModel.from_pretrained(config.BERT_EMBEDDING_ZH)\n",
    "pretrained_bert.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [00:00<00:00, 12207.11it/s]\n",
      "100%|██████████| 247/247 [00:00<00:00, 668.68it/s] \n"
     ]
    }
   ],
   "source": [
    "sample = SerSentenceDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [00:00<00:00, 37382.93it/s]\n",
      "100%|██████████| 247/247 [02:30<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = SerSentenceDataset(data, indexer=SentIdx(tokenizer, pretrained_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7634"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(sample, batch_size=1, shuffle=False, collate_fn=Sent_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(dataloader_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 3851/8540 [01:09<01:16, 61.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3842\n",
      "{'QID': 'D211Q03', 'QTEXT': '1929年世界最高的建筑物是哪一栋摩天大楼?', 'sentence': '加上尖顶后的高度超越了川普大楼成为全世界最高的建筑，', 'other_context': '克莱斯勒大厦是由建筑师威廉‧凡艾伦为沃尔特·克莱斯勒所规划设计。克莱斯勒大厦在1928年9月19日开始动工。大厦的非结构载重性外墙总共用了约400,000万个铆钉，以及约3,826,000个砖块。过程中承建商、建筑工人、工程师和其他建筑专家在共同合作中完成了建造过程。\\n克莱斯勒大厦于1930年5月20日完工，而当时艾菲尔铁塔则是全世界最高的自立构造。克莱斯勒大厦是第一座高度超过1,000英尺（305公尺）的人造建物。凡艾伦虽然缔造了这项创纪录的成就，但沃尔特·克莱斯勒在之后却拒绝支付剩余的建筑费用。1930年5月28日克莱斯勒大厦正式对外开放，不到一年后其高度就被帝国大厦所超越，但克莱斯勒大厦仍然是全世界最高的有钢铁支撑的砖造建筑。2011年11月2日，当时仍在兴建中的世贸中心一号大楼以1,106英尺（337公尺）之高超越了克莱斯勒大厦的高度。', 'context_sents': ['克莱斯勒大厦是由建筑师威廉‧凡艾伦为沃尔特·克莱斯勒所规划设计。', '克莱斯勒大厦在1928年9月19日开始动工。', '大厦的非结构载重性外墙总共用了约400,000万个铆钉，', '以及约3,826,000个砖块。', '过程中承建商、建筑工人、工程师和其他建筑专家在共同合作中完成了建造过程。', '\\n克莱斯勒大厦于1930年5月20日完工，', '而当时艾菲尔铁塔则是全世界最高的自立构造。', '克莱斯勒大厦是第一座高度超过1,000英尺（305公尺）的人造建物。', '凡艾伦虽然缔造了这项创纪录的成就，', '但沃尔特·克莱斯勒在之后却拒绝支付剩余的建筑费用。', '1930年5月28日克莱斯勒大厦正式对外开放，', '不到一年后其高度就被帝国大厦所超越，', '但克莱斯勒大厦仍然是全世界最高的有钢铁支撑的砖造建筑。', '2011年11月2日，', '当时仍在兴建中的世贸中心一号大楼以1,106英尺（337公尺）之高超越了克莱斯勒大厦的高度。'], 'atype': 'Location', 'q_ne': {1: 'DATE', 3: 'NUMBER'}, 'q_piece': ['', '1929年', '世界最高的建筑物是哪', '一', '栋摩天大楼?'], 's_ne': {1: 'AMATCH'}, 's_piece': ['加上尖顶后的高度超越了', '川普大楼', '成为全世界最高的建筑，'], 'label': 1, 'input_ids': [101, 9792, 2399, 686, 4518, 3297, 7770, 4638, 2456, 5029, 4289, 3221, 1525, 671, 3406, 3040, 1921, 1920, 3517, 136, 102, 1217, 677, 2211, 7553, 1400, 4638, 7770, 2428, 6631, 6632, 749, 2335, 3249, 1920, 3517, 2768, 711, 1059, 686, 4518, 3297, 7770, 4638, 2456, 5029, 8024, 102], 'question_ids': [101, 9792, 2399, 686, 4518, 3297, 7770, 4638, 2456, 5029, 4289, 3221, 1525, 671, 3406, 3040, 1921, 1920, 3517, 136, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'tf_match': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0], 'idf_match': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], 'sf_type': [9, 0, 3, 2, 1, 1, 3, 4, 4, 2, 0, 2, 0, 2, 0, 0, 0, 6, 0, 0, 9, 0, 0, 0, 0, 1, 4, 3, 2, 2, 1, 2, 0, 0, 6, 0, 1, 0, 1, 2, 1, 1, 3, 4, 4, 2, 4, 9], 'qsim_type': [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 4, 1, 2, 3, 1, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 1, 3, 0, 1, 0, 0, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 5, 0], 'etype_ids': [0, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'atype_label': 2, 'atype_ent_match': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'sf_score': [1, 1.000001, 0.6666676666666668, 0.8000010000000001, 0.8666676666666667, 0.8666676666666667, 0.6666676666666668, 0.5333343333333334, 0.600001, 0.7333343333333334, 0.9333343333333334, 0.7333343333333334, 1.000001, 0.8000010000000001, 1.000001, 1.000001, 1.000001, 0.400001, 0.9333343333333334, 1.000001, 1, 1.000001, 1.000001, 1.000001, 1.000001, 0.8666676666666667, 0.5333343333333334, 0.6666676666666668, 0.8000010000000001, 0.8000010000000001, 0.8666676666666667, 0.7333343333333334, 1.000001, 1.000001, 0.400001, 0.9333343333333334, 0.8666676666666667, 0.9333343333333334, 0.8666676666666667, 0.8000010000000001, 0.8666676666666667, 0.8666676666666667, 0.6666676666666668, 0.5333343333333334, 0.600001, 0.7333343333333334, 0.600001, 1], 'amatch_type': [0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8540/8540 [02:56<00:00, 49.52it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for s in tqdm(sample):\n",
    "    if s['QID'] == 'D211Q03':\n",
    "        if s['sentence'] == '加上尖顶后的高度超越了川普大楼成为全世界最高的建筑，':\n",
    "            print(i)\n",
    "            print(s)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
