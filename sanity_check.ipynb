{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0409 03:07:19.640415 140273518446400 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.dataset_reader.sentence_group_reader import *\n",
    "from fgc_support_retri.dataset_reader.sentence_reader import *\n",
    "from fgc_support_retri import config\n",
    "from fgc_support_retri.utils import json_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    }
   ],
   "source": [
    "for d_i, d in enumerate(data):\n",
    "    for q in d['QUESTIONS']:\n",
    "        if q['QID'] == 'D313Q01':\n",
    "            print(d_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0409 03:07:21.377386 140273518446400 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0409 03:07:22.326778 140273518446400 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0409 03:07:22.329594 140273518446400 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0409 03:07:23.215267 140273518446400 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_EMBEDDING_ZH)\n",
    "bert = BertModel.from_pretrained(config.BERT_EMBEDDING_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1870.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 777.59it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = SerSentenceDataset([data[237]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D313Q01',\n",
       " 'QTEXT': '内政部消防署提出防范纵火方法「三从四得」，请问是哪「三从」?',\n",
       " 'sentence': '\\n内政部消防署指出，',\n",
       " 'other_context': '最近日本京阿尼动漫遭纵火，造成严重死伤，内政部特别提醒民众，可以依照「三从四得」的方法防范纵火，定期实施安全检查，以确保生命财产安全。\\n根据内政部统计，近10年全台共发生2,535件纵火案，造成164人死亡。纵火犯常见的纵火手法，以明火引燃起火处可燃物占45%为第1位，使用汽油纵火占22%为第2位，但使用汽油纵火案，通常会造成重大伤亡。纵火犯常下手的对象以房屋发生机率最高占49.5%、机车占9.6%、汽车占14.8%。\\n内政部表示，民众可以依照「三从四得」的方法，防范居家或社区大楼的纵火，三从就是「从消除死角做起」、「从守望相助著手」、「从消除杂物动手」；四得就是「可疑状况要认得」、「大门上锁要记得」、「监视设备要舍得」、「灭火方法要晓得」，消防署的网站也有居家消防安全诊断表(https://www.nfa.gov.tw/cht/index.php?code=list&ids=301 )，可供民众下载使用，检视居家的安全。平时各县市政府消防机关，也会针对列管场所定期实施安全检查，以确保公共环境即使被纵火，也不易扩大火势。\\n内政部强调，单靠政府力量防范纵火是不够的，必需要结合民众的力量，加强自主居家消防的安全意识，才能真正减少纵火火灾的伤亡及损失。',\n",
       " 'context_sents': ['最近日本京阿尼动漫遭纵火，',\n",
       "  '造成严重死伤，',\n",
       "  '内政部特别提醒民众，',\n",
       "  '可以依照「三从四得」的方法防范纵火，',\n",
       "  '定期实施安全检查，',\n",
       "  '以确保生命财产安全。',\n",
       "  '\\n根据内政部统计，',\n",
       "  '近10年全台共发生2,535件纵火案，',\n",
       "  '造成164人死亡。',\n",
       "  '纵火犯常见的纵火手法，',\n",
       "  '以明火引燃起火处可燃物占45%为第1位，',\n",
       "  '使用汽油纵火占22%为第2位，',\n",
       "  '但使用汽油纵火案，',\n",
       "  '通常会造成重大伤亡。',\n",
       "  '纵火犯常下手的对象以房屋发生机率最高占49.5%、机车占9.6%、汽车占14.8%。',\n",
       "  '\\n内政部表示，',\n",
       "  '民众可以依照「三从四得」的方法，',\n",
       "  '防范居家或社区大楼的纵火，',\n",
       "  '三从就是「从消除死角做起」、「从守望相助著手」、「从消除杂物动手」；',\n",
       "  '四得就是「可疑状况要认得」、「大门上锁要记得」、「监视设备要舍得」、「灭火方法要晓得」，',\n",
       "  '消防署的网站也有居家消防安全诊断表(https://www.nfa.gov.tw/cht/index.php?code=list&ids=301 )，',\n",
       "  '可供民众下载使用，',\n",
       "  '检视居家的安全。',\n",
       "  '平时各县市政府消防机关，',\n",
       "  '也会针对列管场所定期实施安全检查，',\n",
       "  '以确保公共环境即使被纵火，',\n",
       "  '也不易扩大火势。',\n",
       "  '\\n内政部强调，',\n",
       "  '单靠政府力量防范纵火是不够的，',\n",
       "  '必需要结合民众的力量，',\n",
       "  '加强自主居家消防的安全意识，',\n",
       "  '才能真正减少纵火火灾的伤亡及损失。'],\n",
       " 'atype': 'Object',\n",
       " 'q_ne': {1: 'LOC', 3: 'ORG', 5: 'NUMBER', 7: 'NUMBER', 9: 'NUMBER'},\n",
       " 'q_piece': ['',\n",
       "  '内政部',\n",
       "  '',\n",
       "  '消防署',\n",
       "  '提出防范纵火方法「',\n",
       "  '三',\n",
       "  '从',\n",
       "  '四',\n",
       "  '得」，请问是哪「',\n",
       "  '三',\n",
       "  '从」?'],\n",
       " 's_ne': {1: 'LOC', 3: 'ORG'},\n",
       " 's_piece': ['\\n', '内政部', '', '消防署', '指出，'],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '内政部', '', '消防署', '指出，']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[23]['s_piece']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1079,\n",
       " 3124,\n",
       " 6956,\n",
       " 3867,\n",
       " 7344,\n",
       " 5392,\n",
       " 2990,\n",
       " 1139,\n",
       " 7344,\n",
       " 5745,\n",
       " 5288,\n",
       " 4125,\n",
       " 3175,\n",
       " 3791,\n",
       " 519,\n",
       " 676,\n",
       " 794,\n",
       " 1724,\n",
       " 2533,\n",
       " 520,\n",
       " 8024,\n",
       " 6435,\n",
       " 7309,\n",
       " 3221,\n",
       " 1525,\n",
       " 519,\n",
       " 676,\n",
       " 794,\n",
       " 520,\n",
       " 136,\n",
       " 102,\n",
       " 1079,\n",
       " 3124,\n",
       " 6956,\n",
       " 3867,\n",
       " 7344,\n",
       " 5392,\n",
       " 2900,\n",
       " 1139,\n",
       " 8024,\n",
       " 102]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentIdx(tokenizer, bert)(sample[23])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = SerSGroupDataset(data, transform=torchvision.transforms.Compose([SGroupIdx(tokenizer, bert)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(sample, batch_size=12, shuffle=True, collate_fn=SGroup_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(dataloader_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 96, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['sf_score'].unsqueeze(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0312 04:33:49.814485 139759532590912 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0312 04:33:49.817665 139759532590912 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0312 04:33:50.687346 139759532590912 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 96])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2346,  1.0275,  0.4232,  ...,  0.3071, -0.1894,  0.0218],\n",
       "         [-0.1520,  0.3440,  0.3595,  ..., -0.3183, -0.3259,  0.0587],\n",
       "         [ 0.1665,  0.1313,  0.2115,  ..., -0.1133, -0.2711, -0.2806],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1221,  1.0173,  0.1517,  ...,  0.2913,  0.0085,  0.1280],\n",
       "         [-0.1687,  0.2954,  0.7044,  ..., -0.5417, -0.2595, -0.0528],\n",
       "         [ 0.3971,  0.2900,  0.2430,  ...,  0.1885, -0.4232,  0.0055],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4357,  1.0312,  0.1943,  ...,  0.3674, -0.1535,  0.1093],\n",
       "         [-0.1198,  0.4018,  0.2719,  ..., -0.3908, -0.2624,  0.0582],\n",
       "         [ 0.3997, -0.1245, -0.2792,  ...,  0.2475,  0.1070, -0.3370],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5892,  0.7424,  0.1929,  ...,  0.4418, -0.0915, -0.0560],\n",
       "         [-0.0983,  0.2253,  0.5610,  ..., -0.2999, -0.4762, -0.0846],\n",
       "         [-0.1067, -0.6529, -0.6009,  ...,  1.1190,  0.3796,  0.1749],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4523,  0.8541, -0.1701,  ...,  0.5546,  0.3469,  0.1176],\n",
       "         [-0.7619,  0.7176,  0.3981,  ..., -0.6848,  0.1089, -0.1577],\n",
       "         [-0.1593,  0.2174, -0.1460,  ...,  0.7622,  0.6320,  0.2100],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.2830,  0.9127, -0.2130,  ...,  0.8274, -0.0860,  0.3520],\n",
       "         [ 0.1693,  0.1392,  0.4963,  ..., -0.5282, -0.2118, -0.0349],\n",
       "         [ 0.3729,  0.1978, -0.1095,  ...,  0.4436, -0.0792,  0.4272],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(emb[0], batch['sf_score'].unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
