{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0326 13:17:17.971240 139831343572800 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.ser_extractor import *\n",
    "from fgc_support_retri.utils import *\n",
    "from fgc_support_retri import config\n",
    "from evaluation.fgc_eval import *\n",
    "from evaluation.eval import eval_sp_fgc, eval_fgc_atype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = config.TRAINED_MODELS / \"20200326_sgroup_lr=2e-5\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0326 13:17:26.928295 139831343572800 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0326 13:17:27.828396 139831343572800 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0326 13:17:27.831607 139831343572800 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0326 13:17:28.710637 139831343572800 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0326 13:17:30.908954 139831343572800 modeling_utils.py:457] Weights of SGroupModel not initialized from pretrained model: ['bert.embeddings.add_token_type_embeddings.weight', 'bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'bert.embeddings.ae_match_embeddings.weight', 'classifier.weight', 'classifier.bias']\n",
      "I0326 13:17:30.909981 139831343572800 modeling_utils.py:460] Weights from pretrained model not used in SGroupModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.embeddings.token_type_embeddings.weight']\n",
      "I0326 13:17:36.491445 139831343572800 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0326 13:17:36.497002 139831343572800 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0326 13:17:37.385921 139831343572800 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "extractor = Sgroup_extractor(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = json_load(config.FGC_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:00<00:00, 27544.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '電視名人。為川普集團前任董事長兼總裁', 'text_cn': '电视名人。为川普集团前任董事长兼总裁', 'start': 76, 'end': 94}\n",
      "{'text': '川普娛樂公司的創辦人，在全世界經營房地產', 'text_cn': '川普娱乐公司的创办人，在全世界经营房地产', 'start': 95, 'end': 115}\n",
      "{'text': '熱，電，輻射', 'text_cn': '热，电，辐射', 'start': 22, 'end': 28}\n",
      "{'text': '', 'text_cn': '', 'start': 0, 'end': 0}\n",
      "{'text': '校園注意教室之空氣流通，落實勤洗手，有呼吸道症狀時應配戴口罩；打噴嚏時應用面紙', 'text_cn': '校园注意教室之空气流通，落实勤洗手，有呼吸道症狀时应配戴口罩；打喷嚏时应用面纸', 'start': 88, 'end': 127}\n",
      "{'text': '他人交談時，儘可能保持1公尺以上之距離，避免病毒傳播。', 'text_cn': '他人交谈时，尽可能保持1公尺以上之距离，避免病毒传播。', 'start': 143, 'end': 170}\n",
      "{'text': '', 'text_cn': '', 'start': 0, 'end': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_answer_sp(eval_data, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/882 [00:22<14:10,  1.01it/s]"
     ]
    }
   ],
   "source": [
    "all_sp_predictions = []\n",
    "all_atype_predictions = []\n",
    "all_items = []\n",
    "for d in tqdm(eval_data):\n",
    "    for q in d['QUESTIONS']:\n",
    "        sp_preds, _, sp_scores = extractor.predict(q, d)\n",
    "        q['sp'] = sp_preds\n",
    "        q['sp_scores'] = sp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items, all_sp_predictions, all_answer_sp = eval_from_threshold(eval_data, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = eval_sp_fgc(all_items, all_sp_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = eval_sp_fgc(all_answer_sp, all_sp_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval_span():\n",
    "    intervals = []\n",
    "    last = 0\n",
    "    step = 10\n",
    "    for i in range(step):\n",
    "        now = round(last+1/step, 1)\n",
    "        intervals.append((last, now))\n",
    "        last = now\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval(score):\n",
    "    # get interval span\n",
    "    intervals = []\n",
    "    last = 0\n",
    "    step = 10\n",
    "    for i in range(step):\n",
    "        now = round(last+1/step, 1)\n",
    "        intervals.append((last, now))\n",
    "        last = now\n",
    "    \n",
    "    # get interv_i\n",
    "    for interv_i, interv in enumerate(intervals):\n",
    "        if interv[0] <= score < interv[1]:\n",
    "            return interv_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLabels(data):\n",
    "    all_height = 0\n",
    "    for item in data:\n",
    "        all_height += item.get_height()\n",
    "    for item in data:\n",
    "        height = item.get_height()\n",
    "        plt.text(\n",
    "            item.get_x()+item.get_width()/2., \n",
    "            height*1.05, \n",
    "            '{}% ({})'.format(int(height/all_height*100), int(height)),\n",
    "            ha = \"center\",\n",
    "            va = \"bottom\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = get_interval_span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interv_scores_p = [0] * 10\n",
    "interv_scores_n = [0] * 10\n",
    "interv_scores_answer = [0] * 10\n",
    "interv_scores_not_answer = [0] * 10\n",
    "for document in eval_data:\n",
    "    for question in document['QUESTIONS']:\n",
    "        if not question['SHINT']:\n",
    "            continue\n",
    "        for sent_i, sp_score in enumerate(question['sp_scores']):\n",
    "            if sent_i in question['SHINT']:\n",
    "                interv_scores_p[get_interval(sp_score)] += 1\n",
    "                if sent_i in question['answer_sp']:\n",
    "                    interv_scores_answer[get_interval(sp_score)] += 1\n",
    "                else:\n",
    "                    interv_scores_not_answer[get_interval(sp_score)] += 1\n",
    "            else:\n",
    "                interv_scores_n[get_interval(sp_score)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.subplot(131)\n",
    "A = plt.bar([str(interv[1]) for interv in intervals], interv_scores_p)\n",
    "createLabels(A)\n",
    "plt.title('all sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.subplot(131)\n",
    "B = plt.bar([str(interv[1]) for interv in intervals], interv_scores_n)\n",
    "createLabels(B)\n",
    "plt.title('not sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.subplot(131)\n",
    "B = plt.bar([str(interv[1]) for interv in intervals], interv_scores_answer)\n",
    "createLabels(B)\n",
    "plt.title('answer sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.subplot(131)\n",
    "B = plt.bar([str(interv[1]) for interv in intervals], interv_scores_not_answer)\n",
    "createLabels(B)\n",
    "plt.title('not answer sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
