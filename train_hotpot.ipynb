{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1220 03:33:06.521841 140323447408448 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torchvision\n",
    "import json\n",
    "import torch\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertModel\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri import config\n",
    "from fgc_support_retri.model import BertSentenceSupModel_V2\n",
    "from fgc_support_retri.utils import read_fgc, read_hotpot\n",
    "from fgc_support_retri.fgc_preprocess import BertSentV2Idx, SerSentenceDataset, bert_sentV2_collate\n",
    "from fgc_support_retri.eval import evalaluate_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '进阶题', 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Date-Duration', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申论', 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申论', 'QTEXT': '不可再生能源的意義是什麼？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '不可再生能源的意义是什么？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申论', 'QTEXT': '要如何降低腸病毒的傳播風險？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '要如何降低肠病毒的传播风险？'}\n",
      "25 documents\n",
      "873 sentences\n",
      "34.92 sentences/document\n",
      "18.080183276059564 characters/sentence\n",
      "213 questions\n",
      "485 supporting evidence sentences\n",
      "2.276995305164319 supporting evidence sentences/question\n"
     ]
    }
   ],
   "source": [
    "dev_items = read_fgc(config.FGC_DEV, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1220 03:33:10.225599 140323447408448 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_EMBEDDING)\n",
    "dev_set = SerSentenceDataset(dev_items, transform=torchvision.transforms.Compose([BertSentV2Idx(tokenizer)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D004Q01',\n",
       " 'SENTS': [{'text': '元祐元年（1086年），', 'start': 0, 'end': 12},\n",
       "  {'text': '宋哲宗即位，', 'start': 12, 'end': 18},\n",
       "  {'text': '高太皇太后垂帘听政，', 'start': 18, 'end': 28},\n",
       "  {'text': '回朝任礼部郎中、中书舍人、翰林学士，', 'start': 28, 'end': 46},\n",
       "  {'text': '元祐四年（1089年）拜龙图阁学士，', 'start': 46, 'end': 64},\n",
       "  {'text': '曾出任杭州、颍州等知州职务，', 'start': 64, 'end': 78},\n",
       "  {'text': '官至礼部尚书。', 'start': 78, 'end': 85},\n",
       "  {'text': '\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。', 'start': 85, 'end': 114},\n",
       "  {'text': '\\n元符三年（1100年），', 'start': 114, 'end': 127},\n",
       "  {'text': '宋徽宗即位，', 'start': 127, 'end': 133},\n",
       "  {'text': '向太后垂帘听政，', 'start': 133, 'end': 141},\n",
       "  {'text': '下诏让苏轼北还。', 'start': 141, 'end': 149},\n",
       "  {'text': '\\n建中靖国元年（1101年），', 'start': 149, 'end': 164},\n",
       "  {'text': '夏天因冷饮过度，', 'start': 164, 'end': 172},\n",
       "  {'text': '下痢不止，又误服黄芪，', 'start': 172, 'end': 183},\n",
       "  {'text': '结果病情恶化，', 'start': 183, 'end': 190},\n",
       "  {'text': '「齿间出血如蚯蚓者无数」，', 'start': 190, 'end': 203},\n",
       "  {'text': '七月二十八日于常州孙氏馆病卒，', 'start': 203, 'end': 218},\n",
       "  {'text': '享年六十四岁。', 'start': 218, 'end': 225},\n",
       "  {'text': '由弟苏辙归葬于郏县小峨眉山。', 'start': 225, 'end': 239},\n",
       "  {'text': '南宋宋孝宗追赠谥号「文忠」。', 'start': 239, 'end': 253},\n",
       "  {'text': '\\n苏轼疲于应付新旧党争，', 'start': 253, 'end': 265},\n",
       "  {'text': '遇事「如食内有蝇，吐之乃已」，', 'start': 265, 'end': 280},\n",
       "  {'text': '苏轼既反对王安石比较急进的改革措施，', 'start': 280, 'end': 298},\n",
       "  {'text': '也不同意旧党司马光尽废新法，', 'start': 298, 'end': 312},\n",
       "  {'text': '所以虽然新党一直称苏轼为旧党，', 'start': 312, 'end': 327},\n",
       "  {'text': '但其实他在新旧两党之间均受排斥，', 'start': 327, 'end': 343},\n",
       "  {'text': '仕途坎坷，时常远贬外方，', 'start': 343, 'end': 355},\n",
       "  {'text': '不过他在各地居官清正，', 'start': 355, 'end': 366},\n",
       "  {'text': '为民兴利除弊，', 'start': 366, 'end': 373},\n",
       "  {'text': '政绩颇善，口碑甚佳，', 'start': 373, 'end': 383},\n",
       "  {'text': '杭州西湖的苏堤就是实证。', 'start': 383, 'end': 395}],\n",
       " 'SUP_EVIDENCE': [1, 3, 4, 5, 6],\n",
       " 'QTEXT': '蘇東坡在宋哲宗時期,曾出任過哪些官職?',\n",
       " 'ANS': '禮部郎中、中書舍人、翰林學士、龍圖閣學士、知州與禮部尚書',\n",
       " 'ASPAN': [{'text': '宋哲宗', 'start': 12, 'end': 15},\n",
       "  {'text': '礼部郎中', 'start': 31, 'end': 35},\n",
       "  {'text': '中书舍人', 'start': 36, 'end': 40},\n",
       "  {'text': '翰林学士', 'start': 41, 'end': 45},\n",
       "  {'text': '龙图阁学士', 'start': 58, 'end': 63},\n",
       "  {'text': '知州', 'start': 73, 'end': 75},\n",
       "  {'text': '礼部尚书', 'start': 80, 'end': 84}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sentence_model(num_epochs, batch_size, model_file_name):\n",
    "    \n",
    "    torch.manual_seed(12)\n",
    "    bert_model_name = config.BERT_EMBEDDING\n",
    "    warmup_proportion = 0.1\n",
    "    learning_rate = 5e-5\n",
    "    eval_frequency = 5\n",
    "    \n",
    "    trained_model_path = config.TRAINED_MODELS / model_file_name\n",
    "    if not os.path.exists(trained_model_path):\n",
    "        os.mkdir(trained_model_path)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "\n",
    "    model = BertSentenceSupModel_V2.from_pretrained(bert_model_name)\n",
    "\n",
    "    model.to(device)\n",
    "    if n_gpu > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "    # read data\n",
    "    fgc_items = read_fgc(config.FGC_TRAIN, eval=True)\n",
    "    train_items = fgc_items\n",
    "    dev_items = read_fgc(config.FGC_DEV, eval=True)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "    train_set = SerSentenceDataset(train_items, transform=torchvision.transforms.Compose([BertSentV2Idx(tokenizer)]))\n",
    "    \n",
    "    dataloader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=bert_sentV2_collate)\n",
    "    \n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "    num_train_optimization_steps = int(math.ceil(len(train_set) / batch_size)) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(num_train_optimization_steps*warmup_proportion),\n",
    "                                                num_training_steps=num_train_optimization_steps)\n",
    "    \n",
    "    print('start training ... ')\n",
    "    for epoch_i in range(num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_i, batch in enumerate(tqdm(dataloader_train)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for key in ['input_ids', 'token_type_ids', 'attention_mask', 'tf_type', 'idf_type']:\n",
    "                batch[key] = batch[key].to(device)\n",
    "                \n",
    "            batch['label'] = batch['label'].to(dtype=torch.float, device=device)\n",
    "            loss = model(batch)\n",
    "\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu.\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('epoch %d train_loss: %.3f' % (epoch_i, running_loss/len(dataloader_train)))\n",
    "\n",
    "        if epoch_i % eval_frequency == 0:\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                predictions = []\n",
    "                for item in dev_items:\n",
    "                    train_set = SerSentenceDataset([item], transform=torchvision.transforms.Compose([BertSentV2Idx(tokenizer)]))\n",
    "                    batch = bert_sentV2_collate([sample for sample in train_set])\n",
    "                    for key in ['input_ids', 'token_type_ids', 'attention_mask', 'tf_type', 'idf_type']:\n",
    "                        batch[key] = batch[key].to(device)\n",
    "\n",
    "                    prediction = model.module.predict(batch)\n",
    "                    predictions.append(prediction)\n",
    "\n",
    "                precision, recall, f1 = evalaluate_f1(dev_items, predictions)\n",
    "                print('epoch %d eval_recall: %.3f eval_f1: %.3f' % (epoch_i, recall, f1))\n",
    "\n",
    "                model_to_save = model.module if hasattr(model, 'module') else model\n",
    "                torch.save(model_to_save.state_dict(),\n",
    "                           str(trained_model_path / \"model_epoch{0}_eval_recall_{1:.3f}_f1_{2:.3f}.m\".format(epoch_i, recall, f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1219 12:28:30.212337 140512726615872 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.0c16faba8be66db3f02805c912e4cf94d3c9cffc1f12fa1a39906f9270f76d33\n",
      "I1219 12:28:30.216227 140512726615872 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I1219 12:28:31.052188 140512726615872 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I1219 12:28:33.248439 140512726615872 modeling_utils.py:457] Weights of BertSentenceSupModel_V2 not initialized from pretrained model: ['bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias']\n",
      "I1219 12:28:33.249608 140512726615872 modeling_utils.py:460] Weights from pretrained model not used in BertSentenceSupModel_V2: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gold supporting evidence\n",
      "{'QID': 'D001Q11', 'QTYPE': '申论', 'QTEXT': '蘇東坡為何被後人認為是文學藝術史上的通才?', 'SENTS': [{'text': '苏东坡为何被后人认为是文学艺术史上的通才?', 'start': 0, 'end': 21}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '苏东坡为何被后人认为是文学艺术史上的通才?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D006Q02', 'QTYPE': '申论', 'QTEXT': '「阿拉伯之春」運動中，走上街頭的民眾的訴求為何?', 'SENTS': [{'text': '「阿拉伯之春」运动中，', 'start': 0, 'end': 11}, {'text': '走上街头的民众的诉求为何?', 'start': 11, 'end': 24}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「阿拉伯之春」运动中，走上街头的民众的诉求为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D048Q09', 'QTYPE': '申论', 'QTEXT': '聊天機器人仰賴哪些方法讓回答愈來愈準確?', 'SENTS': [{'text': '聊天机器人仰赖哪些方法让回答愈来愈准确?', 'start': 0, 'end': 20}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '聊天机器人仰赖哪些方法让回答愈来愈准确?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q08', 'QTYPE': '进阶题', 'QTEXT': '妻子的叔叔要怎麼叫他?', 'SENTS': [{'text': '妻子的叔叔要怎么叫他?', 'start': 0, 'end': 11}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '妻子的叔叔要怎么叫他?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q09', 'QTYPE': '进阶题', 'QTEXT': '妻子的叔叔要怎麼稱呼他?', 'SENTS': [{'text': '妻子的叔叔要怎么称呼他?', 'start': 0, 'end': 12}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '妻子的叔叔要怎么称呼他?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q10', 'QTYPE': '进阶题', 'QTEXT': '妻子的嬸嬸要怎麼叫她?', 'SENTS': [{'text': '妻子的婶婶要怎么叫她?', 'start': 0, 'end': 11}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '妻子的婶婶要怎么叫她?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D094Q01', 'QTYPE': '申论', 'QTEXT': '伊甸基金會成立的宗旨為何?', 'SENTS': [{'text': '伊甸基金会成立的宗旨为何?', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '伊甸基金会成立的宗旨为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D103Q07', 'QTYPE': '申论', 'QTEXT': '什麼是「325停課標準」?', 'SENTS': [{'text': '什么是「325停课标准」?', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '什么是「325停课标准」?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D116Q09', 'QTYPE': '进阶题', 'QTEXT': '熬夜是否能減低得到癌症的風險?', 'SENTS': [{'text': '熬夜是否能减低得到癌症的风险?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'YesNo', 'AMODE': 'YesNo', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '熬夜是否能减低得到癌症的风险?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D182Q07', 'QTYPE': '基础题', 'QTEXT': '高屏地區國慶煙火試放管制時間是從晚上幾點開始？', 'SENTS': [{'text': '高屏地区国庆烟火试放管制时间是从晚上几点开始？', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '7時', 'ATOKEN': [{'text': '7时', 'start': 361}], 'ATEXT_CN': '7时'}, {'ATEXT': '7點', 'ATOKEN': [{'text': '7点', 'start': -1}], 'ATEXT_CN': '7点'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '高屏地区国庆烟火试放管制时间是从晚上几点开始？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q03', 'QTYPE': '申论', 'QTEXT': '世界衛生組織表示有哪些因素造成剛果疫情持續升高?', 'SENTS': [{'text': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?', 'start': 0, 'end': 24}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Organization', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q04', 'QTYPE': '申论', 'QTEXT': '疾管署民眾應遵守「二不一要」，請問「二不」是什麼?', 'SENTS': [{'text': '疾管署民众应遵守「二不一要」，', 'start': 0, 'end': 15}, {'text': '请问「二不」是什么?', 'start': 15, 'end': 25}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '疾管署民众应遵守「二不一要」，请问「二不」是什么?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D272Q09', 'QTYPE': '进阶题', 'QTEXT': '毛筆、鉛筆、鋼筆，這三種筆中哪個筆尖的硬度高？', 'SENTS': [{'text': '毛笔、铅笔、钢笔，', 'start': 0, 'end': 9}, {'text': '这三种笔中哪个笔尖的硬度高？', 'start': 9, 'end': 23}], 'ANSWER': [{'ATEXT': '無法判別', 'ATOKEN': [{'text': '无法判别', 'start': -1}], 'ATEXT_CN': '无法判别'}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D288Q12', 'QTYPE': '申论', 'QTEXT': '為什麼古埃及人要把死人做成木乃伊?', 'SENTS': [{'text': '为什么古埃及人要把死人做成木乃伊?', 'start': 0, 'end': 17}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '为什么古埃及人要把死人做成木乃伊?'}\n",
      "100 documents\n",
      "3539 sentences\n",
      "35.39 sentences/document\n",
      "17.565696524441933 characters/sentence\n",
      "738 questions\n",
      "1655 supporting evidence sentences\n",
      "2.2425474254742546 supporting evidence sentences/question\n",
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '进阶题', 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Date-Duration', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申论', 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申论', 'QTEXT': '不可再生能源的意義是什麼？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '不可再生能源的意义是什么？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申论', 'QTEXT': '要如何降低腸病毒的傳播風險？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '要如何降低肠病毒的传播风险？'}\n",
      "25 documents\n",
      "873 sentences\n",
      "34.92 sentences/document\n",
      "18.080183276059564 characters/sentence\n",
      "213 questions\n",
      "485 supporting evidence sentences\n",
      "2.276995305164319 supporting evidence sentences/question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1219 12:28:34.253317 140512726615872 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:04<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train_loss: 0.184\n",
      "epoch 0 eval_recall: 0.324 eval_f1: 0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:00<00:00,  3.10it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss: 0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:00<00:00,  3.07it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train_loss: 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [08:59<00:00,  3.19it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train_loss: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:01<00:00,  2.82it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train_loss: 0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:01<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train_loss: 0.060\n",
      "epoch 5 eval_recall: 0.528 eval_f1: 0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [08:59<00:00,  3.07it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 train_loss: 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [08:57<00:00,  3.03it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 train_loss: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [08:59<00:00,  3.02it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 train_loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [08:59<00:00,  3.14it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 train_loss: 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 train_loss: 0.023\n",
      "epoch 10 eval_recall: 0.478 eval_f1: 0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:07<00:00,  2.88it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 train_loss: 0.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:07<00:00,  3.03it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 train_loss: 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:07<00:00,  3.01it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 train_loss: 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:07<00:00,  3.10it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 train_loss: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:05<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 train_loss: 0.006\n",
      "epoch 15 eval_recall: 0.505 eval_f1: 0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:01<00:00,  3.12it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 train_loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [09:01<00:00,  3.07it/s]\n",
      "  0%|          | 0/1480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 train_loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1080/1480 [06:36<02:23,  2.79it/s]"
     ]
    }
   ],
   "source": [
    "train_sentence_model(20, 18, '20191219_test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2,1)).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
