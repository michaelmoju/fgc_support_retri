{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0210 07:17:45.192024 140690028500800 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (em_model.py, line 220)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3325\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-3-f87cb63a8fc8>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from fgc_support_retri.ser_extractor import *\n",
      "\u001b[0;36m  File \u001b[0;32m\"/work/fgc_support_retri/fgc_support_retri/ser_extractor.py\"\u001b[0;36m, line \u001b[0;32m10\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from nn_model.em_model import EMSERModel\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/work/fgc_support_retri/fgc_support_retri/nn_model/em_model.py\"\u001b[0;36m, line \u001b[0;32m220\u001b[0m\n\u001b[0;31m    def predict_score(self, batch):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from fgc_support_retri.ser_extractor import *\n",
    "from fgc_support_retri.utils import read_fgc, read_hotpot, json_load, json_write\n",
    "from fgc_support_retri import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(config.FGC_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = EMSER_extract(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DID': 'D002',\n",
       " 'QUESTIONS': [{'QID': 'D002Q01',\n",
       "   'QTYPE': '基礎題',\n",
       "   'ATYPE': 'Location',\n",
       "   'AMODE': ['Single-Span-Extraction'],\n",
       "   'QTEXT': '蘇東坡的老家在哪?',\n",
       "   'QTEXT_CN': '苏东坡的老家在哪?',\n",
       "   'SENTS': [{'text': '苏东坡的老家在哪?', 'start': 0, 'end': 9}],\n",
       "   'ANSWER': [{'ATEXT': '蜀',\n",
       "     'ATOKEN': [{'text': '蜀', 'start': 225, 'end': 226}]}],\n",
       "   'ASPAN': [{'text': '苏轼', 'start': 222, 'end': 224},\n",
       "    {'text': '蜀', 'start': 225, 'end': 226},\n",
       "    {'text': '回', 'start': 224, 'end': 225}],\n",
       "   'SHINT': [17, 18]}],\n",
       " 'DTEXT': '嘉佑二年（1057年），蘇軾才20歲，與弟弟蘇轍一同進京參加會考，蘇軾中進士第2名。當時主試官是歐陽脩，蘇軾以一篇《刑賞忠厚之至論》的論文得到考官梅堯臣的青睞，並推薦給主試官歐陽修。歐陽修亦十分讚賞，原本欲拔擢為第一，但又怕該文為自己的門生曾鞏所作，為了避嫌，列為第二。結果試卷拆封後才發現該文為蘇軾所作，而取為第一的是曾鞏，正是陰錯陽差，弄巧成拙。到了禮部複試時，蘇軾再以《春秋對義》居曾鞏之前，中乙科。\\n治平三年（1066年），父蘇洵過世，蘇軾回蜀守喪，英宗憐之，同意以官船載運蘇軾一家。\\n熙寧二年（1069年），任祠部員外郎，反對王安石變法中的一些作為，王安石於是屢次在神宗面前詆毀蘇軾，司馬光、范鎮舉薦蘇軾作諫官，王安石力反之，神宗想讓蘇軾寫起居注，王安石向神宗進言，說蘇軾在回家守喪時，乘機販運蘇木（一種染料），最後神宗放棄這個任命。三年，因為蘇軾一直反對王安石，王安石門下的御史謝景溫又誣陷蘇軾販賣私鹽，范鎮極辯蘇軾販鹽之誣，並願意退休負責。',\n",
       " 'DTEXT_CN': '嘉佑二年（1057年），苏轼才20岁，与弟弟苏辙一同进京参加会考，苏轼中进士第2名。当时主试官是欧阳修，苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，并推荐给主试官欧阳修。欧阳修亦十分赞赏，原本欲拔擢为第一，但又怕该文为自己的门生曾巩所作，为了避嫌，列为第二。结果试卷拆封后才发现该文为苏轼所作，而取为第一的是曾巩，正是阴错阳差，弄巧成拙。到了礼部复试时，苏轼再以《春秋对义》居曾巩之前，中乙科。\\n治平三年（1066年），父苏洵过世，苏轼回蜀守丧，英宗怜之，同意以官船载运苏轼一家。\\n熙宁二年（1069年），任祠部员外郎，反对王安石变法中的一些作为，王安石于是屡次在神宗面前诋毁苏轼，司马光、范镇举荐苏轼作谏官，王安石力反之，神宗想让苏轼写起居注，王安石向神宗进言，说苏轼在回家守丧时，乘机贩运苏木（一种染料），最后神宗放弃这个任命。三年，因为苏轼一直反对王安石，王安石门下的御史谢景温又诬陷苏轼贩卖私盐，范镇极辩苏轼贩盐之诬，并愿意退休负责。',\n",
       " 'SENTS': [{'text': '嘉佑二年（1057年），', 'start': 0, 'end': 12},\n",
       "  {'text': '苏轼才20岁，', 'start': 12, 'end': 19},\n",
       "  {'text': '与弟弟苏辙一同进京参加会考，', 'start': 19, 'end': 33},\n",
       "  {'text': '苏轼中进士第2名。', 'start': 33, 'end': 42},\n",
       "  {'text': '当时主试官是欧阳修，', 'start': 42, 'end': 52},\n",
       "  {'text': '苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，', 'start': 52, 'end': 80},\n",
       "  {'text': '并推荐给主试官欧阳修。', 'start': 80, 'end': 91},\n",
       "  {'text': '欧阳修亦十分赞赏，', 'start': 91, 'end': 100},\n",
       "  {'text': '原本欲拔擢为第一，', 'start': 100, 'end': 109},\n",
       "  {'text': '但又怕该文为自己的门生曾巩所作，', 'start': 109, 'end': 125},\n",
       "  {'text': '为了避嫌，列为第二。', 'start': 125, 'end': 135},\n",
       "  {'text': '结果试卷拆封后才发现该文为苏轼所作，', 'start': 135, 'end': 153},\n",
       "  {'text': '而取为第一的是曾巩，', 'start': 153, 'end': 163},\n",
       "  {'text': '正是阴错阳差，', 'start': 163, 'end': 170},\n",
       "  {'text': '弄巧成拙。到了礼部复试时，', 'start': 170, 'end': 183},\n",
       "  {'text': '苏轼再以《春秋对义》居曾巩之前，', 'start': 183, 'end': 199},\n",
       "  {'text': '中乙科。\\n治平三年（1066年），', 'start': 199, 'end': 216},\n",
       "  {'text': '父苏洵过世，', 'start': 216, 'end': 222},\n",
       "  {'text': '苏轼回蜀守丧，', 'start': 222, 'end': 229},\n",
       "  {'text': '英宗怜之，同意以官船载运苏轼一家。', 'start': 229, 'end': 246},\n",
       "  {'text': '\\n熙宁二年（1069年），', 'start': 246, 'end': 259},\n",
       "  {'text': '任祠部员外郎，', 'start': 259, 'end': 266},\n",
       "  {'text': '反对王安石变法中的一些作为，', 'start': 266, 'end': 280},\n",
       "  {'text': '王安石于是屡次在神宗面前诋毁苏轼，', 'start': 280, 'end': 297},\n",
       "  {'text': '司马光、范镇举荐苏轼作谏官，', 'start': 297, 'end': 311},\n",
       "  {'text': '王安石力反之，', 'start': 311, 'end': 318},\n",
       "  {'text': '神宗想让苏轼写起居注，', 'start': 318, 'end': 329},\n",
       "  {'text': '王安石向神宗进言，', 'start': 329, 'end': 338},\n",
       "  {'text': '说苏轼在回家守丧时，', 'start': 338, 'end': 348},\n",
       "  {'text': '乘机贩运苏木（一种染料），', 'start': 348, 'end': 361},\n",
       "  {'text': '最后神宗放弃这个任命。', 'start': 361, 'end': 372},\n",
       "  {'text': '三年，因为苏轼一直反对王安石，', 'start': 372, 'end': 387},\n",
       "  {'text': '王安石门下的御史谢景温又诬陷苏轼贩卖私盐，', 'start': 387, 'end': 408},\n",
       "  {'text': '范镇极辩苏轼贩盐之诬，', 'start': 408, 'end': 419},\n",
       "  {'text': '并愿意退休负责。', 'start': 419, 'end': 427}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "no gold supporting evidence\n",
      "{'QID': 'D009Q03', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '「佔領華爾街」運動的訴求為何?', 'QTEXT_CN': '「占领华尔街」运动的诉求为何?', 'SENTS': [{'text': '「占领华尔街」运动的诉求为何?', 'start': 0, 'end': 15}]}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q03', 'QTYPE': '申論', 'ATYPE': 'Organization', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '世界衛生組織表示有哪些因素造成剛果疫情持續升高?', 'QTEXT_CN': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?', 'SENTS': [{'text': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?', 'start': 0, 'end': 24}]}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q04', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '疾管署民眾應遵守「二不一要」，請問「二不」是什麼?', 'QTEXT_CN': '疾管署民众应遵守「二不一要」，请问「二不」是什么?', 'SENTS': [{'text': '疾管署民众应遵守「二不一要」，', 'start': 0, 'end': 15}, {'text': '请问「二不」是什么?', 'start': 15, 'end': 25}]}\n",
      "193 documents\n",
      "6271 sentences\n",
      "32.49222797927461 sentences/document\n",
      "18.381438367086588 characters/sentence\n",
      "190 questions\n",
      "532 supporting evidence sentences\n",
      "2.8 supporting evidence sentences/question\n"
     ]
    }
   ],
   "source": [
    "fgc_items = read_fgc(config.FGC_TEST, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0102 06:33:19.303287 140481637357376 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.0c16faba8be66db3f02805c912e4cf94d3c9cffc1f12fa1a39906f9270f76d33\n",
      "I0102 06:33:19.306402 140481637357376 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0102 06:33:20.180576 140481637357376 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0102 06:33:23.320640 140481637357376 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0102 06:33:28.987106 140481637357376 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "100%|██████████| 213/213 [00:18<00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056338028169014086\n",
      "0.024742268041237112\n",
      "0.034383954154727794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = SER_sent_extract_V1()\n",
    "\n",
    "predictions = []\n",
    "predictions = extractor.predict(fgc_items)\n",
    "precision, recall, f1 = evalaluate_f1(fgc_items, predictions)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
