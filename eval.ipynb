{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1223 02:14:15.970679 139666190767936 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.ser_extractor import *\n",
    "from fgc_support_retri.utils import read_fgc, read_hotpot\n",
    "from fgc_support_retri.eval import evalaluate_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SER_sent_extract_V2:\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cpu\")\n",
    "        bert_model_name = config.BERT_EMBEDDING\n",
    "        bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        bert_indexer = BertSentV1Idx(bert_tokenizer)\n",
    "        model = BertSentenceSupModel_V2.from_pretrained(bert_model_name)\n",
    "        model_path = config.TRAINED_MODELS / '20191219_test2' / 'model_epoch20_eval_recall_0.524_f1_0.465.m'\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.model = model\n",
    "        self.bert_indexer = bert_indexer\n",
    "        self.device = device\n",
    "    \n",
    "    def predict(self, items):\n",
    "        predictions = []\n",
    "        for item in tqdm(items):\n",
    "            with torch.no_grad():\n",
    "                train_set = SerSentenceDataset([item], transform=torchvision.transforms.Compose([BertSentV2Idx(self.tokenizer)]))\n",
    "                batch = bert_sentV2_collate([sample for sample in train_set])\n",
    "                for key in ['input_ids', 'token_type_ids', 'attention_mask', 'tf_type', 'idf_type']:\n",
    "                    batch[key] = batch[key].to(self.device)\n",
    "                prediction = self.model.predict(batch, threshold=0.4)\n",
    "                prediction.sort()\n",
    "                item['sup_prediction'] = prediction\n",
    "                predictions.append(prediction)\n",
    "                \n",
    "        return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '进阶题', 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Date-Duration', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申论', 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申论', 'QTEXT': '不可再生能源的意義是什麼？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '不可再生能源的意义是什么？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申论', 'QTEXT': '要如何降低腸病毒的傳播風險？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '要如何降低肠病毒的传播风险？'}\n"
     ]
    }
   ],
   "source": [
    "fgc_items = read_fgc(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1223 02:53:41.984415 139666190767936 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I1223 02:53:42.901609 139666190767936 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.0c16faba8be66db3f02805c912e4cf94d3c9cffc1f12fa1a39906f9270f76d33\n",
      "I1223 02:53:42.904864 139666190767936 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I1223 02:53:43.789413 139666190767936 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I1223 02:53:45.881884 139666190767936 modeling_utils.py:457] Weights of BertSentenceSupModel_V2 not initialized from pretrained model: ['bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias']\n",
      "I1223 02:53:45.884176 139666190767936 modeling_utils.py:460] Weights from pretrained model not used in BertSentenceSupModel_V2: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e17199ef4d468fae89bb787c667f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=213), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.4184514003294893\n",
      "0.5237113402061856\n",
      "0.46520146520146516\n"
     ]
    }
   ],
   "source": [
    "extractor = SER_sent_extract_V2()\n",
    "\n",
    "predictions = []\n",
    "predictions = extractor.predict(fgc_items)\n",
    "precision, recall, f1 = evalaluate_f1(fgc_items, predictions)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in fgc_items:\n",
    "    \n",
    "    new_sents = []\n",
    "    for s_i, s in enumerate(item['SENTS']):\n",
    "        new_sents.append({s_i: s['text']})\n",
    "    del item['SENTS']\n",
    "    item['SENTS'] = new_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D011Q02',\n",
       " 'SUP_EVIDENCE': [9, 16],\n",
       " 'QTEXT': '形成於北大西洋的熱帶氣旋，又被稱為什麼？',\n",
       " 'ANS': '颶風',\n",
       " 'ASPAN': [{'text': '北大西洋', 'start': 417, 'end': 421},\n",
       "  {'text': '飓风', 'start': 424, 'end': 426},\n",
       "  {'text': '热带气旋', 'start': 247, 'end': 251},\n",
       "  {'text': '台风', 'start': 281, 'end': 283},\n",
       "  {'text': '台风', 'start': 413, 'end': 415},\n",
       "  {'text': '北太平洋', 'start': 404, 'end': 408}],\n",
       " 'sup_prediction': [16],\n",
       " 'SENTS': [{0: '台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태풍/台风/taepung）是赤道以北，'},\n",
       "  {1: '国际换日线以西，'},\n",
       "  {2: '亚太国家或地区对热带气旋的一个分级。'},\n",
       "  {3: '在气象学上，'},\n",
       "  {4: '按世界气象组织定义，'},\n",
       "  {5: '热带气旋中心持续风速达到12级（即64节或以上、32.7m/s或以上，又或者118km/hr或以上）称为飓风（Hurricane）或其他在地近义字。'},\n",
       "  {6: '西北太平洋地区采用之近义字乃台风。'},\n",
       "  {7: '\\n广义上，「台风」这个词并非一种热带气旋强度。'},\n",
       "  {8: '在台湾、日本等地，'},\n",
       "  {9: '将中心持续风速每秒17.2米或以上的热带气旋（包括世界气象组织定义中的热带风暴、强烈热带风暴和台风）均称台风。'},\n",
       "  {10: '在非正式场合，'},\n",
       "  {11: '「台风」甚至直接泛指热带气旋本身。'},\n",
       "  {12: '当西北太平洋的热带气旋达到热带风暴的强度，'},\n",
       "  {13: '区域专责气象中心（RSMC）日本气象厅会对其编号及命名，'},\n",
       "  {14: '名称由世界气象组织台风委员会的14个国家和地区提供。'},\n",
       "  {15: '\\n但在不同海洋上也各自有地区性的名称，'},\n",
       "  {16: '例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgc_items[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
