{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1220 06:38:14.415892 139918188459840 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.ser_extractor import *\n",
    "from fgc_support_retri.utils import read_fgc, read_hotpot\n",
    "from fgc_support_retri.eval import evalaluate_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SER_sent_extract_V2:\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cpu\")\n",
    "        bert_model_name = config.BERT_EMBEDDING\n",
    "        bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        bert_indexer = BertSentV1Idx(bert_tokenizer)\n",
    "        model = BertSentenceSupModel_V2.from_pretrained(bert_model_name)\n",
    "        model_path = config.TRAINED_MODELS / '20191219_test2' / 'model_epoch20_eval_recall_0.524_f1_0.465.m'\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.model = model\n",
    "        self.bert_indexer = bert_indexer\n",
    "        self.device = device\n",
    "    \n",
    "    def predict(self, items):\n",
    "        predictions = []\n",
    "        for item in tqdm(items):\n",
    "            with torch.no_grad():\n",
    "                train_set = SerSentenceDataset([item], transform=torchvision.transforms.Compose([BertSentV2Idx(self.tokenizer)]))\n",
    "                batch = bert_sentV2_collate([sample for sample in train_set])\n",
    "                for key in ['input_ids', 'token_type_ids', 'attention_mask', 'tf_type', 'idf_type']:\n",
    "                    batch[key] = batch[key].to(self.device)\n",
    "                prediction = self.model.predict(batch, threshold=0.5)\n",
    "                prediction.sort()\n",
    "                item['sup_prediction'] = prediction\n",
    "                predictions.append(prediction)\n",
    "                \n",
    "        return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '进阶题', 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Date-Duration', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申论', 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申论', 'QTEXT': '不可再生能源的意義是什麼？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '不可再生能源的意义是什么？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申论', 'QTEXT': '要如何降低腸病毒的傳播風險？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '要如何降低肠病毒的传播风险？'}\n"
     ]
    }
   ],
   "source": [
    "fgc_items = read_fgc(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1220 06:38:15.843599 139918188459840 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I1220 06:38:23.559087 139918188459840 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.0c16faba8be66db3f02805c912e4cf94d3c9cffc1f12fa1a39906f9270f76d33\n",
      "I1220 06:38:23.562205 139918188459840 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I1220 06:38:24.629658 139918188459840 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I1220 06:38:27.029927 139918188459840 modeling_utils.py:457] Weights of BertSentenceSupModel_V2 not initialized from pretrained model: ['bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias']\n",
      "I1220 06:38:27.032667 139918188459840 modeling_utils.py:460] Weights from pretrained model not used in BertSentenceSupModel_V2: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f1905507d04556b4c4889409fcf513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=213), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.4293785310734463\n",
      "0.47010309278350515\n",
      "0.44881889763779526\n"
     ]
    }
   ],
   "source": [
    "extractor = SER_sent_extract_V2()\n",
    "\n",
    "predictions = []\n",
    "predictions = extractor.predict(fgc_items)\n",
    "precision, recall, f1 = evalaluate_f1(fgc_items, predictions)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6db129be98f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnew_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SENTS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mnew_sents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ms_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SENTS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SENTS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "for item in fgc_items:\n",
    "    \n",
    "    new_sents = []\n",
    "    for s_i, s in enumerate(item['SENTS']):\n",
    "        new_sents.append({s_i: s['text']})\n",
    "    del item['SENTS']\n",
    "    item['SENTS'] = new_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D004Q07',\n",
       " 'SUP_EVIDENCE': [11, 19],\n",
       " 'QTEXT': '蘇東坡死後葬在哪裡?',\n",
       " 'ANS': '郟縣小峨眉山',\n",
       " 'ASPAN': [{'text': '葬', 'start': 230, 'end': 231},\n",
       "  {'text': '郏县', 'start': 232, 'end': 234},\n",
       "  {'text': '小峨眉山', 'start': 234, 'end': 238},\n",
       "  {'text': '苏轼', 'start': 144, 'end': 146}],\n",
       " 'sup_prediction': [19],\n",
       " 'SENTS': [{0: '元祐元年（1086年），'},\n",
       "  {1: '宋哲宗即位，'},\n",
       "  {2: '高太皇太后垂帘听政，'},\n",
       "  {3: '回朝任礼部郎中、中书舍人、翰林学士，'},\n",
       "  {4: '元祐四年（1089年）拜龙图阁学士，'},\n",
       "  {5: '曾出任杭州、颍州等知州职务，'},\n",
       "  {6: '官至礼部尚书。'},\n",
       "  {7: '\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。'},\n",
       "  {8: '\\n元符三年（1100年），'},\n",
       "  {9: '宋徽宗即位，'},\n",
       "  {10: '向太后垂帘听政，'},\n",
       "  {11: '下诏让苏轼北还。'},\n",
       "  {12: '\\n建中靖国元年（1101年），'},\n",
       "  {13: '夏天因冷饮过度，'},\n",
       "  {14: '下痢不止，又误服黄芪，'},\n",
       "  {15: '结果病情恶化，'},\n",
       "  {16: '「齿间出血如蚯蚓者无数」，'},\n",
       "  {17: '七月二十八日于常州孙氏馆病卒，'},\n",
       "  {18: '享年六十四岁。'},\n",
       "  {19: '由弟苏辙归葬于郏县小峨眉山。'},\n",
       "  {20: '南宋宋孝宗追赠谥号「文忠」。'},\n",
       "  {21: '\\n苏轼疲于应付新旧党争，'},\n",
       "  {22: '遇事「如食内有蝇，吐之乃已」，'},\n",
       "  {23: '苏轼既反对王安石比较急进的改革措施，'},\n",
       "  {24: '也不同意旧党司马光尽废新法，'},\n",
       "  {25: '所以虽然新党一直称苏轼为旧党，'},\n",
       "  {26: '但其实他在新旧两党之间均受排斥，'},\n",
       "  {27: '仕途坎坷，时常远贬外方，'},\n",
       "  {28: '不过他在各地居官清正，'},\n",
       "  {29: '为民兴利除弊，'},\n",
       "  {30: '政绩颇善，口碑甚佳，'},\n",
       "  {31: '杭州西湖的苏堤就是实证。'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgc_items[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
