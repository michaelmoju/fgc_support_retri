{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0317 01:51:51.845125 140574716786496 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgc_support_retri.ser_extractor import *\n",
    "from fgc_support_retri.utils import read_fgc, read_hotpot, json_load, json_write\n",
    "from fgc_support_retri import config\n",
    "from evaluation.eval import eval_sp_fgc, eval_fgc_atype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0317 01:51:58.895591 140574716786496 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0317 01:51:59.861984 140574716786496 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0317 01:51:59.864810 140574716786496 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0317 01:52:00.800085 140574716786496 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0317 01:52:03.019869 140574716786496 modeling_utils.py:457] Weights of EntityMatchModel not initialized from pretrained model: ['bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'bert.embeddings.ae_match_embeddings.weight', 'classifier.weight', 'classifier.bias']\n",
      "I0317 01:52:03.020948 140574716786496 modeling_utils.py:460] Weights from pretrained model not used in EntityMatchModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I0317 01:52:08.517465 140574716786496 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0317 01:52:08.522675 140574716786496 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0317 01:52:09.390527 140574716786496 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "extractor = EntityMatch_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(config.FGC_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [02:59<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "all_sp_predictions = []\n",
    "all_atype_predictions = []\n",
    "for d in tqdm(data):\n",
    "    for q in d['QUESTIONS']:\n",
    "        sp_preds, _, sp_scores = extractor.predict(q, d)\n",
    "        all_sp_predictions.append(sp_preds)\n",
    "        q['sp'] = sp_preds\n",
    "        q['sp_scores'] = sp_scores\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print(d)\n",
    "#             break\n",
    "#     all_atype_predictions += atypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:00<00:00, 73994.58it/s]\n"
     ]
    }
   ],
   "source": [
    "all_items = []\n",
    "for d in tqdm(data):\n",
    "    for q in d['QUESTIONS']:\n",
    "        all_items.append(q['SHINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.17616580310880828, 'sp_prec': 0.616627600954026, 'sp_recall': 0.5957685664939552, 'sp_f1': 0.5605767577270172}\n"
     ]
    }
   ],
   "source": [
    "metrics = eval_sp_fgc(all_items, all_sp_predictions)\n",
    "# atype_accuracy = eval_fgc_atype(all_items, all_atype_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/work/fgc_support_retri/data/FGC/FGC_release_1.7.7/FGC_release_all_test.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.FGC_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_write(data, 'FGC_release_all_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = []\n",
    "questions = []\n",
    "t_sp = []\n",
    "p_sp = []\n",
    "\n",
    "q_idx = 0 \n",
    "for document in data:\n",
    "    for question in document['QUESTIONS']:\n",
    "        question['sp_predict'] = all_sp_predictions[q_idx]\n",
    "        q_idx +=1\n",
    "        \n",
    "        qids.append(question['QID'])\n",
    "        questions.append(question['QTEXT_CN'])\n",
    "        t_sp_text = []\n",
    "        p_sp_text = []\n",
    "        for idx in question['SHINT']:\n",
    "            t_sp_text.append(document['SENTS'][idx]['text'])\n",
    "        for idx in question['sp_predict']:\n",
    "            p_sp_text.append(document['SENTS'][idx]['text'])\n",
    "        t_sp.append(t_sp_text)\n",
    "        p_sp.append(p_sp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.DataFrame(index=qids)\n",
    "pred_df['question'] = questions\n",
    "pred_df['t_sp'] = t_sp\n",
    "pred_df['p_sp'] = p_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>t_sp</th>\n",
       "      <th>p_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>D003Q01</td>\n",
       "      <td>上官均是否赞成王安石的新政改革?</td>\n",
       "      <td>[因发现上官均的策论有诋毁王安石变法的情况，]</td>\n",
       "      <td>[便改上官均为第二名。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D003Q02</td>\n",
       "      <td>苏东坡因为什么事件入狱几乎要死在狱中?</td>\n",
       "      <td>[因乌台诗案入狱，, 几死，因为写文章向朝廷诀别，]</td>\n",
       "      <td>[因乌台诗案入狱，, 神宗动心，苏轼终免一死，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D003Q03</td>\n",
       "      <td>在「乌台诗案」中，有哪些人出面救了苏东坡？</td>\n",
       "      <td>[几死，因为写文章向朝廷诀别，, 太皇太后曹氏、王安礼等人出面力挽，, 神宗动心，苏轼终免一死，]</td>\n",
       "      <td>[苏轼参加救灾。, 太皇太后曹氏、王安礼等人出面力挽，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D003Q04</td>\n",
       "      <td>苏东坡因「乌台诗案」被贬到什么地方？</td>\n",
       "      <td>[因乌台诗案入狱，, 神宗动心，苏轼终免一死，, 翌年被贬至黄州（今湖北省黄冈市），]</td>\n",
       "      <td>[因乌台诗案入狱，, 贬谪为「检校尚书水部员外郎黄州团练副使本州安置」，, 翌年被贬至黄州（...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D003Q05</td>\n",
       "      <td>宋神宗熙宁十月，黄河溃堤时，苏东坡人在哪里？</td>\n",
       "      <td>[熙宁十年四月，, 赴任徐州，是年七月七日，, 黄河决口，水困徐州，, 苏轼参加救灾。]</td>\n",
       "      <td>[熙宁三年（1070年），, 熙宁十年四月，]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       question  \\\n",
       "D003Q01        上官均是否赞成王安石的新政改革?   \n",
       "D003Q02     苏东坡因为什么事件入狱几乎要死在狱中?   \n",
       "D003Q03   在「乌台诗案」中，有哪些人出面救了苏东坡？   \n",
       "D003Q04      苏东坡因「乌台诗案」被贬到什么地方？   \n",
       "D003Q05  宋神宗熙宁十月，黄河溃堤时，苏东坡人在哪里？   \n",
       "\n",
       "                                                      t_sp  \\\n",
       "D003Q01                            [因发现上官均的策论有诋毁王安石变法的情况，]   \n",
       "D003Q02                         [因乌台诗案入狱，, 几死，因为写文章向朝廷诀别，]   \n",
       "D003Q03  [几死，因为写文章向朝廷诀别，, 太皇太后曹氏、王安礼等人出面力挽，, 神宗动心，苏轼终免一死，]   \n",
       "D003Q04        [因乌台诗案入狱，, 神宗动心，苏轼终免一死，, 翌年被贬至黄州（今湖北省黄冈市），]   \n",
       "D003Q05       [熙宁十年四月，, 赴任徐州，是年七月七日，, 黄河决口，水困徐州，, 苏轼参加救灾。]   \n",
       "\n",
       "                                                      p_sp  \n",
       "D003Q01                                       [便改上官均为第二名。]  \n",
       "D003Q02                           [因乌台诗案入狱，, 神宗动心，苏轼终免一死，]  \n",
       "D003Q03                       [苏轼参加救灾。, 太皇太后曹氏、王安礼等人出面力挽，]  \n",
       "D003Q04  [因乌台诗案入狱，, 贬谪为「检校尚书水部员外郎黄州团练副使本州安置」，, 翌年被贬至黄州（...  \n",
       "D003Q05                            [熙宁三年（1070年），, 熙宁十年四月，]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('em_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8798076923076923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atype_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(data):\n",
    "    item = extractor.get_item(d)\n",
    "    items= [i for i in item]\n",
    "    for q_id, item in enumerate(items):\n",
    "        score_list = extractor.predict_score(item)\n",
    "        d['QUESTIONS'][q_id]['s_score'] = score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_write(data, str(config.RESULT_PATH/\"prediction\"/\"FGC_3_weeks_sup.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(config.DATA_ROOT/\"FGC\"/\"FGC_3_weeks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DID': 'D001',\n",
       " 'DTEXT': '蘇軾（1037年1月8日－1101年8月24日），眉州眉山（今四川省眉山市）人，北宋時著名的文學家、政治家、藝術家、醫學家。字子瞻，一字和仲，號東坡居士、鐵冠道人。嘉佑二年進士，累官至端明殿學士兼翰林學士，禮部尚書。南宋理學方熾時，加賜諡號文忠，複追贈太師。有《東坡先生大全集》及《東坡樂府》詞集傳世，宋人王宗稷收其作品，編有《蘇文忠公全集》。\\n其散文、詩、詞、賦均有成就，且善書法和繪畫，是文學藝術史上的通才，也是公認韻文散文造詣皆比較傑出的大家。蘇軾的散文為唐宋四家（韓愈、柳宗元、歐蘇）之末，與唐代的古文運動發起者韓愈並稱為「韓潮蘇海」，也與歐陽修並稱「歐蘇」；更與父親蘇洵、弟蘇轍合稱「三蘇」，父子三人，同列唐宋八大家。蘇軾之詩與黃庭堅並稱「蘇黃」，又與陸游並稱「蘇陸」；其詞「以詩入詞」，首開詞壇「豪放」一派，振作了晚唐、五代以來綺靡的西崑體餘風。後世與南宋辛棄疾並稱「蘇辛」，惟蘇軾故作豪放，其實清朗；其賦亦頗有名氣，最知名者為貶謫期間借題發揮寫的前後《赤壁賦》。宋代每逢科考常出現其文命題之考試，故當時學者曰：「蘇文熟，喫羊肉、蘇文生，嚼菜羹」。藝術方面，書法名列「蘇、黃、米、蔡」北宋四大書法家（宋四家）之首；其畫則開創了湖州畫派；並在題畫文學史上佔有舉足輕重的地位。',\n",
       " 'QUESTIONS': [{'QID': 'D001Q09',\n",
       "   'QTYPE': '基礎題',\n",
       "   'QTEXT': '辛棄疾是哪一個朝代的人？',\n",
       "   'ANSWER': [{'ATEXT': '南宋', 'ATEXT_CN': '南宋'}],\n",
       "   'QTEXT_CN': '辛弃疾是哪一个朝代的人？',\n",
       "   'QTEXT_RE': '辛弃疾是哪一个朝代的人？',\n",
       "   'REFINED': 0.9,\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ATYPE': 'Date-Duration',\n",
       "   's_score': [0.18831099569797516,\n",
       "    0.00017647468484938145,\n",
       "    0.0009485816117376089,\n",
       "    0.00013792241225019097,\n",
       "    8.458553929813206e-05,\n",
       "    8.222580800065771e-05,\n",
       "    0.00010341336019337177,\n",
       "    0.00013554444012697786,\n",
       "    7.037891919026151e-05,\n",
       "    0.00010389492672402412,\n",
       "    7.310201181098819e-05,\n",
       "    8.71824158821255e-05,\n",
       "    7.090889994287863e-05,\n",
       "    6.984685751376674e-05,\n",
       "    8.315293962368742e-05,\n",
       "    0.00014165780157782137,\n",
       "    7.56292647565715e-05,\n",
       "    0.05508154258131981,\n",
       "    0.00012093309487681836,\n",
       "    9.921458695316687e-05,\n",
       "    8.145817264448851e-05,\n",
       "    7.237419777084142e-05,\n",
       "    7.230976189021021e-05,\n",
       "    7.233589712996036e-05,\n",
       "    7.50215767766349e-05,\n",
       "    7.787355571053922e-05,\n",
       "    0.00010627166921040043,\n",
       "    0.9918557405471802,\n",
       "    8.666922803968191e-05,\n",
       "    8.780533244134858e-05,\n",
       "    0.00010498654592083767,\n",
       "    0.00010938803461613134,\n",
       "    0.00017313110583927482,\n",
       "    0.00017912955081555992,\n",
       "    7.017419557087123e-05,\n",
       "    7.308201747946441e-05]}],\n",
       " 'DTEXT_CN': '苏轼（1037年1月8日－1101年8月24日），眉州眉山（今四川省眉山市）人，北宋时著名的文学家、政治家、艺术家、医学家。字子瞻，一字和仲，号东坡居士、铁冠道人。嘉佑二年进士，累官至端明殿学士兼翰林学士，礼部尚书。南宋理学方炽时，加赐谥号文忠，复追赠太师。有《东坡先生大全集》及《东坡乐府》词集传世，宋人王宗稷收其作品，编有《苏文忠公全集》。\\n其散文、诗、词、赋均有成就，且善书法和绘画，是文学艺术史上的通才，也是公认韵文散文造诣皆比较杰出的大家。苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，与唐代的古文运动发起者韩愈并称为「韩潮苏海」，也与欧阳修并称「欧苏」；更与父亲苏洵、弟苏辙合称「三苏」，父子三人，同列唐宋八大家。苏轼之诗与黄庭坚并称「苏黄」，又与陆游并称「苏陆」；其词「以诗入词」，首开词坛「豪放」一派，振作了晚唐、五代以来绮靡的西昆体余风。后世与南宋辛弃疾并称「苏辛」，惟苏轼故作豪放，其实清朗；其赋亦颇有名气，最知名者为贬谪期间借题发挥写的前后《赤壁赋》。宋代每逢科考常出现其文命题之考试，故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；其画则开创了湖州画派；并在题画文学史上占有举足轻重的地位。',\n",
       " 'DTEXT_RE': '苏轼（1037年1月8日－1101年8月24日），眉州眉山（今四川省眉山市）人，北宋时著名的文学家、政治家、艺术家、医学家。字子瞻，一字和仲，号东坡居士、铁冠道人。嘉佑二年进士，累官至端明殿学士兼翰林学士，礼部尚书。南宋理学方炽时，加赐谥号文忠，复追赠太师。有《东坡先生大全集》及《东坡乐府》词集传世，宋人王宗稷收其作品，编有《苏文忠公全集》。\\n其散文、诗、词、赋均有成就，且善书法和绘画，是文学艺术史上的通才，也是公认韵文散文造诣皆比较杰出的大家。苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，与唐代的古文运动发起者韩愈并称为「韩潮苏海」，也与欧阳修并称「欧苏」；更与父亲苏洵、弟苏辙合称「三苏」，父子三人，同列唐宋八大家。苏轼之诗与黄庭坚并称「苏黄」，又与陆游并称「苏陆」；其词「以诗入词」，首开词坛「豪放」一派，振作了晚唐、五代以来绮靡的西昆体余风。后世与南宋辛弃疾并称「苏辛」，惟苏轼故作豪放，其实清朗；其赋亦颇有名气，最知名者为贬谪期间借题发挥写的前后《赤壁赋》。宋代每逢科考常出现其文命题之考试，故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；其画则开创了湖州画派；并在题画文学史上占有举足轻重的地位。',\n",
       " 'REFINED': 0.9,\n",
       " 'SENTS': [{'text': '苏轼（1037年1月8日－1101年8月24日），', 'start': 0, 'end': 25},\n",
       "  {'text': '眉州眉山（今四川省眉山市）人，', 'start': 25, 'end': 40},\n",
       "  {'text': '北宋时著名的文学家、政治家、艺术家、医学家。', 'start': 40, 'end': 62},\n",
       "  {'text': '字子瞻，一字和仲，', 'start': 62, 'end': 71},\n",
       "  {'text': '号东坡居士、铁冠道人。', 'start': 71, 'end': 82},\n",
       "  {'text': '嘉佑二年进士，', 'start': 82, 'end': 89},\n",
       "  {'text': '累官至端明殿学士兼翰林学士，', 'start': 89, 'end': 103},\n",
       "  {'text': '礼部尚书。南宋理学方炽时，', 'start': 103, 'end': 116},\n",
       "  {'text': '加赐谥号文忠，', 'start': 116, 'end': 123},\n",
       "  {'text': '复追赠太师。', 'start': 123, 'end': 129},\n",
       "  {'text': '有《东坡先生大全集》及《东坡乐府》词集传世，', 'start': 129, 'end': 151},\n",
       "  {'text': '宋人王宗稷收其作品，', 'start': 151, 'end': 161},\n",
       "  {'text': '编有《苏文忠公全集》。', 'start': 161, 'end': 172},\n",
       "  {'text': '\\n其散文、诗、词、赋均有成就，', 'start': 172, 'end': 187},\n",
       "  {'text': '且善书法和绘画，', 'start': 187, 'end': 195},\n",
       "  {'text': '是文学艺术史上的通才，', 'start': 195, 'end': 206},\n",
       "  {'text': '也是公认韵文散文造诣皆比较杰出的大家。', 'start': 206, 'end': 225},\n",
       "  {'text': '苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，', 'start': 225, 'end': 249},\n",
       "  {'text': '与唐代的古文运动发起者韩愈并称为「韩潮苏海」，', 'start': 249, 'end': 272},\n",
       "  {'text': '也与欧阳修并称「欧苏」；', 'start': 272, 'end': 284},\n",
       "  {'text': '更与父亲苏洵、弟苏辙合称「三苏」，', 'start': 284, 'end': 301},\n",
       "  {'text': '父子三人，同列唐宋八大家。', 'start': 301, 'end': 314},\n",
       "  {'text': '苏轼之诗与黄庭坚并称「苏黄」，', 'start': 314, 'end': 329},\n",
       "  {'text': '又与陆游并称「苏陆」；', 'start': 329, 'end': 340},\n",
       "  {'text': '其词「以诗入词」，', 'start': 340, 'end': 349},\n",
       "  {'text': '首开词坛「豪放」一派，', 'start': 349, 'end': 360},\n",
       "  {'text': '振作了晚唐、五代以来绮靡的西昆体余风。', 'start': 360, 'end': 379},\n",
       "  {'text': '后世与南宋辛弃疾并称「苏辛」，', 'start': 379, 'end': 394},\n",
       "  {'text': '惟苏轼故作豪放，', 'start': 394, 'end': 402},\n",
       "  {'text': '其实清朗；其赋亦颇有名气，', 'start': 402, 'end': 415},\n",
       "  {'text': '最知名者为贬谪期间借题发挥写的前后《赤壁赋》。', 'start': 415, 'end': 438},\n",
       "  {'text': '宋代每逢科考常出现其文命题之考试，', 'start': 438, 'end': 455},\n",
       "  {'text': '故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。', 'start': 455, 'end': 480},\n",
       "  {'text': '艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；', 'start': 480, 'end': 513},\n",
       "  {'text': '其画则开创了湖州画派；', 'start': 513, 'end': 524},\n",
       "  {'text': '并在题画文学史上占有举足轻重的地位。', 'start': 524, 'end': 542}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 524/1254 [00:27<01:13,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:3_445-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1064/1254 [01:04<00:17, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_21053-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [01:21<00:00, 10.76it/s]\n",
      "100%|██████████| 8014/8014 [1:00:12<00:00,  1.49it/s]\n",
      "100%|██████████| 1000/1000 [08:48<00:00,  3.01it/s]\n",
      "100%|██████████| 1254/1254 [01:22<00:00, 15.15it/s]\n",
      " 61%|██████▏   | 491/800 [00:08<00:05, 53.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_10162-1\n",
      "tokenized all > 511 id:7_10163-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 563/800 [00:09<00:04, 54.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_21032-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:13<00:00, 62.06it/s]\n",
      " 43%|████▎     | 2957/6832 [02:43<07:08,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:3_444-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 5729/6832 [05:58<02:02,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_21054-1\n",
      "tokenized all > 511 id:7_21057-1\n",
      "tokenized all > 511 id:7_21058-1\n",
      "tokenized all > 511 id:7_21059-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6832/6832 [07:35<00:00, 14.99it/s]\n",
      " 36%|███▌      | 1569/4360 [00:26<00:47, 58.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_592-1\n",
      "tokenized all > 511 id:1_593-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1611/4360 [00:27<00:43, 63.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_661-1\n",
      "tokenized all > 511 id:1_662-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1723/4360 [00:28<00:43, 60.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_904-1\n",
      "tokenized all > 511 id:1_907-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1736/4360 [00:29<00:45, 57.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_923-1\n",
      "tokenized all > 511 id:1_924-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1810/4360 [00:30<00:51, 49.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_1068-1\n",
      "tokenized all > 511 id:1_1079-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1893/4360 [00:31<00:41, 59.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_1190-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2321/4360 [00:38<00:36, 55.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:2_2357-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 2339/4360 [00:39<00:37, 54.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:2_2409-1\n",
      "tokenized all > 511 id:2_2410-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2433/4360 [00:40<00:34, 55.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:2_3068-1\n",
      "tokenized all > 511 id:2_3070-1\n",
      "tokenized all > 511 id:2_3080-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2734/4360 [00:45<00:30, 54.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_10160-1\n",
      "tokenized all > 511 id:7_10161-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 2878/4360 [00:48<00:28, 52.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_10939-1\n",
      "tokenized all > 511 id:7_10941-1\n",
      "tokenized all > 511 id:7_10942-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 2992/4360 [00:50<00:25, 53.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_11426-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3102/4360 [00:52<00:23, 52.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_21033-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3200/4360 [00:54<00:21, 54.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_21332-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3224/4360 [00:54<00:21, 53.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:7_21410-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 3597/4360 [01:01<00:14, 53.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:5_1052-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 3609/4360 [01:01<00:14, 52.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:5_1078-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 3688/4360 [01:02<00:12, 52.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:5_1286-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 3754/4360 [01:04<00:11, 51.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:5_1471-1\n",
      "tokenized all > 511 id:5_1474-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4360/4360 [01:14<00:00, 58.84it/s]\n",
      " 41%|████      | 326/800 [00:05<00:07, 60.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:1_1067-1\n",
      "tokenized all > 511 id:1_1076-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 428/800 [00:07<00:06, 55.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:2_2358-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 704/800 [00:12<00:01, 53.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized all > 511 id:5_1476-1\n",
      "tokenized all > 511 id:5_1477-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:13<00:00, 57.35it/s]\n",
      "100%|██████████| 124/124 [00:16<00:00,  4.24it/s]\n",
      "100%|██████████| 1000/1000 [08:11<00:00,  3.24it/s]\n",
      "100%|██████████| 145/145 [00:19<00:00,  9.09it/s]\n",
      "100%|██████████| 711/711 [01:22<00:00,  8.60it/s]\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(config.DATA_ROOT/\"release_1.7\"/\"DRCD\")\n",
    "files = [f for f in files if f.endswith(\".json\")]\n",
    "\n",
    "for f in files:\n",
    "    data = json_load(config.DATA_ROOT/\"release_1.7\"/\"DRCD\"/f)\n",
    "    for d in tqdm(data):\n",
    "        item = extractor.get_item(d)\n",
    "        items= [i for i in item]\n",
    "        for q_id, item in enumerate(items):\n",
    "            score_list = extractor.predict_score(item)\n",
    "            d['QUESTIONS'][q_id]['s_score'] = score_list\n",
    "    json_write(data, str(config.RESULT_PATH/\"prediction\"/(f[:-5]+\"_sup.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
