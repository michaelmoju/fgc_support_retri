{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1211 05:31:07.330024 140436334675776 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from sup_model import BertForMultiHopQuestionAnswering, BertSupTagModel\n",
    "from utils import read_fgc\n",
    "from fgc_preprocess import BertSpanTagIdx, SerContextDataset, bert_context_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SER_context_extract:\n",
    "    def __init__(self):\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        bert_model_name = 'bert-base-chinese'\n",
    "        bert_encoder = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        model = BertSupTagModel(bert_encoder, device)\n",
    "        model_path = config.TRAINED_MODELS / '20191210_BertSupTag'/ 'model_epoch5_loss_0.360.m' \n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        self.indexer = BertSpanTagIdx(bert_tokenizer)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        \n",
    "    def predict(self, context_sents, question):\n",
    "        sample = self.indexer({'QTEXT': question, 'SENTS': context_sents})\n",
    "        item = bert_context_collate([sample])\n",
    "        with torch.no_grad():\n",
    "            input_ids = item['input_ids'].to(self.device)\n",
    "            token_type_ids = item['token_type_ids'].to(self.device)\n",
    "            attention_mask = item['attention_mask'].to(self.device)\n",
    "            logits = self.model(input_ids=input_ids, \n",
    "                                token_type_ids=token_type_ids,\n",
    "                                attention_mask=attention_mask, \n",
    "                                mode=BertSupTagModel.ForwardMode.EVAL)\n",
    "            tag_list = logits[0].cpu().numpy()\n",
    "            \n",
    "            sep_positions = [None] * len(sample['sentence_position'])\n",
    "            for position, sid in sample['sentence_position'].items():\n",
    "                sep_positions[sid] = position\n",
    "            \n",
    "            prediction = []\n",
    "            for tid, tag in enumerate(tag_list):\n",
    "                if tag == 1:\n",
    "                    for sid in range(len(sep_positions)-1):\n",
    "                        if sep_positions[sid] < tid < sep_positions[sid+1]:\n",
    "                            prediction.append(sid)\n",
    "        return prediction \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1211 06:51:13.323674 140436334675776 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.0c16faba8be66db3f02805c912e4cf94d3c9cffc1f12fa1a39906f9270f76d33\n",
      "I1211 06:51:13.326623 140436334675776 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I1211 06:51:24.674311 140436334675776 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I1211 06:51:29.824921 140436334675776 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "extractor = SER_context_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalaluate(fgc_items):\n",
    "    tp = 0\n",
    "    gol_t = 0\n",
    "    pre_t = 0\n",
    "    for data in tqdm(fgc_items):\n",
    "        prediction = extractor.predict(data['SENTS'], data['QTEXT'])\n",
    "        gold = data['SUP_EVIDENCE']\n",
    "        pred = prediction\n",
    "        \n",
    "        gol_t += len(gold)\n",
    "        pre_t += len(pred)\n",
    "        for g in gold:\n",
    "            if g in pred:\n",
    "                tp += 1\n",
    "        data['prediction'] = prediction\n",
    "                \n",
    "    precision = tp / pre_t\n",
    "    recall = tp / gol_t\n",
    "\n",
    "    f1 = 2*precision*recall / (precision+recall)\n",
    "\n",
    "    print(\"precision = {}\".format(precision))\n",
    "    print(\"recall = {}\".format(recall))\n",
    "    print(\"f1 = {}\".format(f1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '进阶题', 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Date-Duration', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申论', 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申论', 'QTEXT': '不可再生能源的意義是什麼？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '不可再生能源的意义是什么？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申论', 'QTEXT': '要如何降低腸病毒的傳播風險？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '要如何降低肠病毒的传播风险？'}\n"
     ]
    }
   ],
   "source": [
    "fgc_train_items = read_fgc(config.FGC_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d45b7ea8c3e490cb7cb745e674e1e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=213), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.32172701949860727\n",
      "recall = 0.4762886597938144\n",
      "f1 = 0.38403990024937656\n"
     ]
    }
   ],
   "source": [
    "evalaluate(fgc_train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QID': 'D001Q02',\n",
       " 'SENTS': [{'text': '苏轼（1037年1月8日－1101年8月24日），', 'start': 0, 'end': 25},\n",
       "  {'text': '眉州眉山（今四川省眉山市）人，', 'start': 25, 'end': 40},\n",
       "  {'text': '北宋时著名的文学家、政治家、艺术家、医学家。', 'start': 40, 'end': 62},\n",
       "  {'text': '字子瞻，一字和仲，', 'start': 62, 'end': 71},\n",
       "  {'text': '号东坡居士、铁冠道人。', 'start': 71, 'end': 82},\n",
       "  {'text': '嘉佑二年进士，', 'start': 82, 'end': 89},\n",
       "  {'text': '累官至端明殿学士兼翰林学士，', 'start': 89, 'end': 103},\n",
       "  {'text': '礼部尚书。南宋理学方炽时，', 'start': 103, 'end': 116},\n",
       "  {'text': '加赐谥号文忠，', 'start': 116, 'end': 123},\n",
       "  {'text': '复追赠太师。', 'start': 123, 'end': 129},\n",
       "  {'text': '有《东坡先生大全集》及《东坡乐府》词集传世，', 'start': 129, 'end': 151},\n",
       "  {'text': '宋人王宗稷收其作品，', 'start': 151, 'end': 161},\n",
       "  {'text': '编有《苏文忠公全集》。', 'start': 161, 'end': 172},\n",
       "  {'text': '\\n其散文、诗、词、赋均有成就，', 'start': 172, 'end': 187},\n",
       "  {'text': '且善书法和绘画，', 'start': 187, 'end': 195},\n",
       "  {'text': '是文学艺术史上的通才，', 'start': 195, 'end': 206},\n",
       "  {'text': '也是公认韵文散文造诣皆比较杰出的大家。', 'start': 206, 'end': 225},\n",
       "  {'text': '苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，', 'start': 225, 'end': 249},\n",
       "  {'text': '与唐代的古文运动发起者韩愈并称为「韩潮苏海」，', 'start': 249, 'end': 272},\n",
       "  {'text': '也与欧阳修并称「欧苏」；', 'start': 272, 'end': 284},\n",
       "  {'text': '更与父亲苏洵、弟苏辙合称「三苏」，', 'start': 284, 'end': 301},\n",
       "  {'text': '父子三人，同列唐宋八大家。', 'start': 301, 'end': 314},\n",
       "  {'text': '苏轼之诗与黄庭坚并称「苏黄」，', 'start': 314, 'end': 329},\n",
       "  {'text': '又与陆游并称「苏陆」；', 'start': 329, 'end': 340},\n",
       "  {'text': '其词「以诗入词」，', 'start': 340, 'end': 349},\n",
       "  {'text': '首开词坛「豪放」一派，', 'start': 349, 'end': 360},\n",
       "  {'text': '振作了晚唐、五代以来绮靡的西昆体余风。', 'start': 360, 'end': 379},\n",
       "  {'text': '后世与南宋辛弃疾并称「苏辛」，', 'start': 379, 'end': 394},\n",
       "  {'text': '惟苏轼故作豪放，', 'start': 394, 'end': 402},\n",
       "  {'text': '其实清朗；其赋亦颇有名气，', 'start': 402, 'end': 415},\n",
       "  {'text': '最知名者为贬谪期间借题发挥写的前后《赤壁赋》。', 'start': 415, 'end': 438},\n",
       "  {'text': '宋代每逢科考常出现其文命题之考试，', 'start': 438, 'end': 455},\n",
       "  {'text': '故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。', 'start': 455, 'end': 480},\n",
       "  {'text': '艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；', 'start': 480, 'end': 513},\n",
       "  {'text': '其画则开创了湖州画派；', 'start': 513, 'end': 524},\n",
       "  {'text': '并在题画文学史上占有举足轻重的地位。', 'start': 524, 'end': 542}],\n",
       " 'SUP_EVIDENCE': [0, 1, 4],\n",
       " 'QTEXT': '蘇東坡是中國哪個省份的人？',\n",
       " 'ANS': '四川省',\n",
       " 'ASPAN': [{'text': '苏轼', 'start': 0, 'end': 2},\n",
       "  {'text': '四川省', 'start': 31, 'end': 34},\n",
       "  {'text': '东坡居士', 'start': 72, 'end': 76}],\n",
       " 'prediction': [0, 1, 2, 4]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgc_train_items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
