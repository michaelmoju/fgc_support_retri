{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0214 03:24:39.152928 139941226334016 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')\n",
    "from fgc_support_retri.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0214 03:24:40.637109 139941226334016 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0214 03:24:40.641416 139941226334016 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0214 03:24:41.543249 139941226334016 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0214 03:24:43.963331 139941226334016 modeling_utils.py:457] Weights of SynSERModel not initialized from pretrained model: ['bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'bert.embeddings.sf_type_embeddings.weight', 'bert.embeddings.qsim_embeddings.weight', 'classifier.weight', 'classifier.bias']\n",
      "I0214 03:24:43.966149 139941226334016 modeling_utils.py:460] Weights from pretrained model not used in SynSERModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I0214 03:24:44.843109 139941226334016 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0214 03:24:44.846602 139941226334016 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0214 03:24:45.722374 139941226334016 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "no gold supporting evidence\n",
      "{'QID': 'D001Q11', 'QTYPE': '申论', 'QTEXT': '蘇東坡為何被後人認為是文學藝術史上的通才?', 'SENTS': [{'text': '苏东坡为何被后人认为是文学艺术史上的通才?', 'start': 0, 'end': 21}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '苏东坡为何被后人认为是文学艺术史上的通才?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D006Q02', 'QTYPE': '申论', 'QTEXT': '「阿拉伯之春」運動中，走上街頭的民眾的訴求為何?', 'SENTS': [{'text': '「阿拉伯之春」运动中，', 'start': 0, 'end': 11}, {'text': '走上街头的民众的诉求为何?', 'start': 11, 'end': 24}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「阿拉伯之春」运动中，走上街头的民众的诉求为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D048Q09', 'QTYPE': '申论', 'QTEXT': '聊天機器人仰賴哪些方法讓回答愈來愈準確?', 'SENTS': [{'text': '聊天机器人仰赖哪些方法让回答愈来愈准确?', 'start': 0, 'end': 20}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '聊天机器人仰赖哪些方法让回答愈来愈准确?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q08', 'QTYPE': '进阶题', 'QTEXT': '妻子的叔叔要怎麼叫他?', 'SENTS': [{'text': '妻子的叔叔要怎么叫他?', 'start': 0, 'end': 11}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '妻子的叔叔要怎么叫他?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q09', 'QTYPE': '进阶题', 'QTEXT': '妻子的叔叔要怎麼稱呼他?', 'SENTS': [{'text': '妻子的叔叔要怎么称呼他?', 'start': 0, 'end': 12}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '妻子的叔叔要怎么称呼他?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D091Q10', 'QTYPE': '进阶题', 'QTEXT': '妻子的嬸嬸要怎麼叫她?', 'SENTS': [{'text': '妻子的婶婶要怎么叫她?', 'start': 0, 'end': 11}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '妻子的婶婶要怎么叫她?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D094Q01', 'QTYPE': '申论', 'QTEXT': '伊甸基金會成立的宗旨為何?', 'SENTS': [{'text': '伊甸基金会成立的宗旨为何?', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '伊甸基金会成立的宗旨为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D103Q07', 'QTYPE': '申论', 'QTEXT': '什麼是「325停課標準」?', 'SENTS': [{'text': '什么是「325停课标准」?', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '什么是「325停课标准」?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D116Q09', 'QTYPE': '进阶题', 'QTEXT': '熬夜是否能減低得到癌症的風險?', 'SENTS': [{'text': '熬夜是否能减低得到癌症的风险?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'YesNo', 'AMODE': 'YesNo', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '熬夜是否能减低得到癌症的风险?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D182Q07', 'QTYPE': '基础题', 'QTEXT': '高屏地區國慶煙火試放管制時間是從晚上幾點開始？', 'SENTS': [{'text': '高屏地区国庆烟火试放管制时间是从晚上几点开始？', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '7時', 'ATOKEN': [{'text': '7时', 'start': 361}], 'ATEXT_CN': '7时'}, {'ATEXT': '7點', 'ATOKEN': [{'text': '7点', 'start': -1}], 'ATEXT_CN': '7点'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '高屏地区国庆烟火试放管制时间是从晚上几点开始？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q03', 'QTYPE': '申论', 'QTEXT': '世界衛生組織表示有哪些因素造成剛果疫情持續升高?', 'SENTS': [{'text': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?', 'start': 0, 'end': 24}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Organization', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q04', 'QTYPE': '申论', 'QTEXT': '疾管署民眾應遵守「二不一要」，請問「二不」是什麼?', 'SENTS': [{'text': '疾管署民众应遵守「二不一要」，', 'start': 0, 'end': 15}, {'text': '请问「二不」是什么?', 'start': 15, 'end': 25}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '疾管署民众应遵守「二不一要」，请问「二不」是什么?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D272Q09', 'QTYPE': '进阶题', 'QTEXT': '毛筆、鉛筆、鋼筆，這三種筆中哪個筆尖的硬度高？', 'SENTS': [{'text': '毛笔、铅笔、钢笔，', 'start': 0, 'end': 9}, {'text': '这三种笔中哪个笔尖的硬度高？', 'start': 9, 'end': 23}], 'ANSWER': [{'ATEXT': '無法判別', 'ATOKEN': [{'text': '无法判别', 'start': -1}], 'ATEXT_CN': '无法判别'}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D288Q12', 'QTYPE': '申论', 'QTEXT': '為什麼古埃及人要把死人做成木乃伊?', 'SENTS': [{'text': '为什么古埃及人要把死人做成木乃伊?', 'start': 0, 'end': 17}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '为什么古埃及人要把死人做成木乃伊?'}\n",
      "25\n",
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '进阶题', 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATOKEN': [{'text': '资讯不足无法判定', 'start': -1}], 'ATEXT_CN': '资讯不足无法判定'}], 'ATYPE': 'Date-Duration', 'AMODE': 'Date-Duration', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D049Q04', 'QTYPE': '申论', 'QTEXT': '「雅婷逐字稿」的命名起源為何?', 'SENTS': [{'text': '「雅婷逐字稿」的命名起源为何?', 'start': 0, 'end': 15}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Event', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '「雅婷逐字稿」的命名起源为何?'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申论', 'QTEXT': '不可再生能源的意義是什麼？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Object', 'AMODE': 'Single-Span-Extraction', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '不可再生能源的意义是什么？'}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申论', 'QTEXT': '要如何降低腸病毒的傳播風險？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'ANSWER': [{'ATEXT': '', 'ATOKEN': [{'text': '', 'start': 0}], 'ATEXT_CN': ''}], 'ATYPE': 'Kinship', 'AMODE': 'Kinship', 'ASPAN': [], 'SHINT': [], 'QTEXT_CN': '要如何降低肠病毒的传播风险？'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0214 03:24:53.453822 139941226334016 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "  0%|          | 0/2219 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 2219/2219 [18:35<00:00,  2.18it/s]\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train_loss: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [03:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.107981220657277, 'sp_prec': 0.4975468975468977, 'sp_recall': 0.5480326402861616, 'sp_f1': 0.4509426931962144}\n",
      "epoch 0 eval_recall: 0.548 eval_f1: 0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2219/2219 [18:29<00:00,  1.54it/s]\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss: 0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [03:12<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.18309859154929578, 'sp_prec': 0.5034987704001789, 'sp_recall': 0.3651128996199419, 'sp_f1': 0.3952157388777106}\n",
      "epoch 1 eval_recall: 0.365 eval_f1: 0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2219/2219 [20:06<00:00,  1.86it/s]\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train_loss: 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [04:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.2112676056338028, 'sp_prec': 0.5678515537670469, 'sp_recall': 0.47391012743125444, 'sp_f1': 0.47857888069155674}\n",
      "epoch 2 eval_recall: 0.474 eval_f1: 0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2219/2219 [21:18<00:00,  1.88it/s]\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train_loss: 0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [04:06<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.13145539906103287, 'sp_prec': 0.5214136671883152, 'sp_recall': 0.4896825396825398, 'sp_f1': 0.45411052171615574}\n",
      "epoch 3 eval_recall: 0.490 eval_f1: 0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2219/2219 [18:43<00:00,  1.90it/s]\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train_loss: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [03:48<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.16901408450704225, 'sp_prec': 0.5279752589611746, 'sp_recall': 0.4817907444668009, 'sp_f1': 0.4557881086050103}\n",
      "epoch 4 eval_recall: 0.482 eval_f1: 0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2219/2219 [18:27<00:00,  2.11it/s]\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train_loss: 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [03:36<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.17370892018779344, 'sp_prec': 0.5520120724346077, 'sp_recall': 0.5228593784931814, 'sp_f1': 0.49271927863477166}\n",
      "epoch 5 eval_recall: 0.523 eval_f1: 0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 639/2219 [05:17<11:46,  2.24it/s]"
     ]
    }
   ],
   "source": [
    "train_SynSERModel(10, 12, \"20200214_syn_all\", \"syn-all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
