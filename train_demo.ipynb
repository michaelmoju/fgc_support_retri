{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir)\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 02:20:51.407612 140524117194560 file_utils.py:39] PyTorch version 1.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(w_dir+'/fgc_support_retri')\n",
    "from fgc_support_retri.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 02:20:52.819057 140524117194560 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0303 02:20:53.754254 140524117194560 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0303 02:20:53.758090 140524117194560 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0303 02:20:54.628092 140524117194560 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0303 02:20:57.633894 140524117194560 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.3767c74c8ed285531d04153fe84a0791672aff52f7249b27df341dbce09b8305\n",
      "I0303 02:20:57.638231 140524117194560 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0303 02:20:58.658297 140524117194560 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0303 02:21:00.806425 140524117194560 modeling_utils.py:457] Weights of EntitySERModel not initialized from pretrained model: ['bert.embeddings.tf_embeddings.weight', 'bert.embeddings.idf_embeddings.weight', 'bert.embeddings.etype_embeddings.weight', 'classifier.weight', 'classifier.bias']\n",
      "I0303 02:21:00.807473 140524117194560 modeling_utils.py:460] Weights from pretrained model not used in EntitySERModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882\n",
      "no gold supporting evidence\n",
      "{'QID': 'D006Q02', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '「阿拉伯之春」運動中，走上街頭的民眾的訴求為何?', 'QTEXT_CN': '「阿拉伯之春」运动中，走上街头的民众的诉求为何?', 'SENTS': [{'text': '「阿拉伯之春」运动中，', 'start': 0, 'end': 11}, {'text': '走上街头的民众的诉求为何?', 'start': 11, 'end': 24}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '阿拉伯之春', 'type': 'MISC', 'char_b': 1, 'char_e': 6}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '「', 'char_b': 0, 'char_e': 1, 'pos': 'PU'}, {'word': '阿拉伯', 'char_b': 1, 'char_e': 4, 'pos': 'NR'}, {'word': '之', 'char_b': 4, 'char_e': 5, 'pos': 'DEG'}, {'word': '春', 'char_b': 5, 'char_e': 6, 'pos': 'NN'}, {'word': '」', 'char_b': 6, 'char_e': 7, 'pos': 'PU'}, {'word': '运动中', 'char_b': 7, 'char_e': 10, 'pos': 'NN'}, {'word': '，', 'char_b': 10, 'char_e': 11, 'pos': 'PU'}, {'word': '走上', 'char_b': 11, 'char_e': 13, 'pos': 'VV'}, {'word': '街头', 'char_b': 13, 'char_e': 15, 'pos': 'NN'}, {'word': '的', 'char_b': 15, 'char_e': 16, 'pos': 'DEC'}, {'word': '民众', 'char_b': 16, 'char_e': 18, 'pos': 'NN'}, {'word': '的', 'char_b': 18, 'char_e': 19, 'pos': 'DEG'}, {'word': '诉求', 'char_b': 19, 'char_e': 21, 'pos': 'NN'}, {'word': '为何', 'char_b': 21, 'char_e': 23, 'pos': 'AD'}, {'word': '?', 'char_b': 23, 'char_e': 24, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D032Q10', 'QTYPE': '進階題', 'ATYPE': 'Date-Duration', 'AMODE': ['Date-Duration'], 'QTEXT': '第二次簽訂的北美貿易協定從簽署至生效過了幾日?', 'QTEXT_CN': '第二次签订的北美贸易协定从签署至生效过了几日?', 'SENTS': [{'text': '第二次签订的北美贸易协定从签署至生效过了几日?', 'start': 0, 'end': 23}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '第二', 'type': 'ORDINAL', 'char_b': 0, 'char_e': 2}, {'id': 'D0-S0-M1', 'string': '北美', 'type': 'LOC', 'char_b': 6, 'char_e': 8}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '第二', 'char_b': 0, 'char_e': 2, 'pos': 'OD'}, {'word': '次', 'char_b': 2, 'char_e': 3, 'pos': 'M'}, {'word': '签订', 'char_b': 3, 'char_e': 5, 'pos': 'VV'}, {'word': '的', 'char_b': 5, 'char_e': 6, 'pos': 'DEC'}, {'word': '北美', 'char_b': 6, 'char_e': 8, 'pos': 'NR'}, {'word': '贸易', 'char_b': 8, 'char_e': 10, 'pos': 'NN'}, {'word': '协定', 'char_b': 10, 'char_e': 12, 'pos': 'NN'}, {'word': '从', 'char_b': 12, 'char_e': 13, 'pos': 'P'}, {'word': '签署', 'char_b': 13, 'char_e': 15, 'pos': 'VV'}, {'word': '至', 'char_b': 15, 'char_e': 16, 'pos': 'P'}, {'word': '生效', 'char_b': 16, 'char_e': 18, 'pos': 'VV'}, {'word': '过', 'char_b': 18, 'char_e': 19, 'pos': 'AS'}, {'word': '了', 'char_b': 19, 'char_e': 20, 'pos': 'AS'}, {'word': '几日', 'char_b': 20, 'char_e': 22, 'pos': 'NN'}, {'word': '?', 'char_b': 22, 'char_e': 23, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATEXT_CN': '资讯不足无法判定', 'ATOKEN': [{'text': '資訊不足無法判定', 'text_cn': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D048Q09', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '聊天機器人仰賴哪些方法讓回答愈來愈準確?', 'QTEXT_CN': '聊天机器人仰赖哪些方法让回答愈来愈准确?', 'SENTS': [{'text': '聊天机器人仰赖哪些方法让回答愈来愈准确?', 'start': 0, 'end': 20}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '聊天', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '机器人', 'char_b': 2, 'char_e': 5, 'pos': 'NN'}, {'word': '仰赖', 'char_b': 5, 'char_e': 7, 'pos': 'VV'}, {'word': '哪些', 'char_b': 7, 'char_e': 9, 'pos': 'DT'}, {'word': '方法', 'char_b': 9, 'char_e': 11, 'pos': 'NN'}, {'word': '让', 'char_b': 11, 'char_e': 12, 'pos': 'VV'}, {'word': '回答', 'char_b': 12, 'char_e': 14, 'pos': 'VV'}, {'word': '愈来愈', 'char_b': 14, 'char_e': 17, 'pos': 'AD'}, {'word': '准确', 'char_b': 17, 'char_e': 19, 'pos': 'VA'}, {'word': '?', 'char_b': 19, 'char_e': 20, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D086Q03', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '不可再生能源的意義是什麼？', 'QTEXT_CN': '不可再生能源的意义是什么？', 'SENTS': [{'text': '不可再生能源的意义是什么？', 'start': 0, 'end': 13}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '不', 'char_b': 0, 'char_e': 1, 'pos': 'AD'}, {'word': '可再生', 'char_b': 1, 'char_e': 4, 'pos': 'JJ'}, {'word': '能源', 'char_b': 4, 'char_e': 6, 'pos': 'NN'}, {'word': '的', 'char_b': 6, 'char_e': 7, 'pos': 'DEG'}, {'word': '意义', 'char_b': 7, 'char_e': 9, 'pos': 'NN'}, {'word': '是', 'char_b': 9, 'char_e': 10, 'pos': 'VC'}, {'word': '什么', 'char_b': 10, 'char_e': 12, 'pos': 'PN'}, {'word': '？', 'char_b': 12, 'char_e': 13, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D094Q01', 'QTYPE': '申論', 'ATYPE': 'Event', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '伊甸基金會成立的宗旨為何?', 'QTEXT_CN': '伊甸基金会成立的宗旨为何?', 'SENTS': [{'text': '伊甸基金会成立的宗旨为何?', 'start': 0, 'end': 13}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '伊甸基金会', 'type': 'ORG', 'char_b': 0, 'char_e': 5}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '伊甸', 'char_b': 0, 'char_e': 2, 'pos': 'NR'}, {'word': '基金会', 'char_b': 2, 'char_e': 5, 'pos': 'NN'}, {'word': '成立', 'char_b': 5, 'char_e': 7, 'pos': 'VV'}, {'word': '的', 'char_b': 7, 'char_e': 8, 'pos': 'DEC'}, {'word': '宗旨', 'char_b': 8, 'char_e': 10, 'pos': 'NN'}, {'word': '为何', 'char_b': 10, 'char_e': 12, 'pos': 'AD'}, {'word': '?', 'char_b': 12, 'char_e': 13, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D116Q09', 'QTYPE': '進階題', 'ATYPE': 'YesNo', 'AMODE': ['YesNo'], 'QTEXT': '熬夜是否能減低得到癌症的風險?', 'QTEXT_CN': '熬夜是否能减低得到癌症的风险?', 'SENTS': [{'text': '熬夜是否能减低得到癌症的风险?', 'start': 0, 'end': 15}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '癌症', 'type': 'CAUSE_OF_DEATH', 'char_b': 9, 'char_e': 11}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '熬夜', 'char_b': 0, 'char_e': 2, 'pos': 'VV'}, {'word': '是否', 'char_b': 2, 'char_e': 4, 'pos': 'AD'}, {'word': '能', 'char_b': 4, 'char_e': 5, 'pos': 'VV'}, {'word': '减低', 'char_b': 5, 'char_e': 7, 'pos': 'VV'}, {'word': '得到', 'char_b': 7, 'char_e': 9, 'pos': 'VV'}, {'word': '癌症', 'char_b': 9, 'char_e': 11, 'pos': 'NN'}, {'word': '的', 'char_b': 11, 'char_e': 12, 'pos': 'DEC'}, {'word': '风险', 'char_b': 12, 'char_e': 14, 'pos': 'NN'}, {'word': '?', 'char_b': 14, 'char_e': 15, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '資訊不足無法判定', 'ATEXT_CN': '资讯不足无法判定', 'ATOKEN': [{'text': '資訊不足無法判定', 'text_cn': '资讯不足无法判定', 'start': -1, 'end': 7}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D182Q07', 'QTYPE': '基礎題', 'ATYPE': 'Date-Duration', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '高屏地區國慶煙火試放管制時間是從晚上幾點開始？', 'QTEXT_CN': '高屏地区国庆烟火试放管制时间是从晚上几点开始？', 'SENTS': [{'text': '高屏地区国庆烟火试放管制时间是从晚上几点开始？', 'start': 0, 'end': 23}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '国庆烟火试放管制时间', 'type': 'MISC', 'char_b': 4, 'char_e': 14}, {'id': 'D0-S0-M1', 'string': '晚上', 'type': 'TIME', 'char_b': 16, 'char_e': 18}, {'id': 'D0-S0-M2', 'string': '几', 'type': 'NUMBER', 'char_b': 18, 'char_e': 19}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '高屏', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '地区', 'char_b': 2, 'char_e': 4, 'pos': 'NN'}, {'word': '国庆', 'char_b': 4, 'char_e': 6, 'pos': 'NN'}, {'word': '烟火', 'char_b': 6, 'char_e': 8, 'pos': 'NN'}, {'word': '试放', 'char_b': 8, 'char_e': 10, 'pos': 'VV'}, {'word': '管制', 'char_b': 10, 'char_e': 12, 'pos': 'NN'}, {'word': '时间', 'char_b': 12, 'char_e': 14, 'pos': 'NN'}, {'word': '是', 'char_b': 14, 'char_e': 15, 'pos': 'VC'}, {'word': '从', 'char_b': 15, 'char_e': 16, 'pos': 'P'}, {'word': '晚上', 'char_b': 16, 'char_e': 18, 'pos': 'NT'}, {'word': '几', 'char_b': 18, 'char_e': 19, 'pos': 'CD'}, {'word': '点', 'char_b': 19, 'char_e': 20, 'pos': 'M'}, {'word': '开始', 'char_b': 20, 'char_e': 22, 'pos': 'VV'}, {'word': '？', 'char_b': 22, 'char_e': 23, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '7時', 'ATEXT_CN': '7时', 'ATOKEN': [{'text': '7時', 'text_cn': '7时', 'start': 361, 'end': 363}]}, {'ATEXT': '7點', 'ATEXT_CN': '7点', 'ATOKEN': [{'text': '7點', 'text_cn': '7点', 'start': -1, 'end': 1}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D245Q05', 'QTYPE': '申論', 'ATYPE': 'Event', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '為何聖伯多祿大殿只能重建不能整修就好?', 'QTEXT_CN': '为何圣伯多禄大殿只能重建不能整修就好?', 'SENTS': [{'text': '为何圣伯多禄大殿只能重建不能整修就好?', 'start': 0, 'end': 19}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '为何', 'char_b': 0, 'char_e': 2, 'pos': 'AD'}, {'word': '圣伯多禄', 'char_b': 2, 'char_e': 6, 'pos': 'NR'}, {'word': '大殿', 'char_b': 6, 'char_e': 8, 'pos': 'NN'}, {'word': '只', 'char_b': 8, 'char_e': 9, 'pos': 'AD'}, {'word': '能', 'char_b': 9, 'char_e': 10, 'pos': 'VV'}, {'word': '重建', 'char_b': 10, 'char_e': 12, 'pos': 'VV'}, {'word': '不', 'char_b': 12, 'char_e': 13, 'pos': 'AD'}, {'word': '能', 'char_b': 13, 'char_e': 14, 'pos': 'VV'}, {'word': '整修', 'char_b': 14, 'char_e': 16, 'pos': 'VV'}, {'word': '就好', 'char_b': 16, 'char_e': 18, 'pos': 'VV'}, {'word': '?', 'char_b': 18, 'char_e': 19, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D272Q09', 'QTYPE': '進階題', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '毛筆、鉛筆、鋼筆，這三種筆中哪個筆尖的硬度高？', 'QTEXT_CN': '毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？', 'SENTS': [{'text': '毛笔、铅笔、钢笔，', 'start': 0, 'end': 9}, {'text': '这三种笔中哪个笔尖的硬度高？', 'start': 9, 'end': 23}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '三', 'type': 'NUMBER', 'char_b': 10, 'char_e': 11}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '毛笔', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '、', 'char_b': 2, 'char_e': 3, 'pos': 'PU'}, {'word': '铅笔', 'char_b': 3, 'char_e': 5, 'pos': 'NN'}, {'word': '、', 'char_b': 5, 'char_e': 6, 'pos': 'PU'}, {'word': '钢笔', 'char_b': 6, 'char_e': 8, 'pos': 'NN'}, {'word': '，', 'char_b': 8, 'char_e': 9, 'pos': 'PU'}, {'word': '这', 'char_b': 9, 'char_e': 10, 'pos': 'DT'}, {'word': '三', 'char_b': 10, 'char_e': 11, 'pos': 'CD'}, {'word': '种', 'char_b': 11, 'char_e': 12, 'pos': 'M'}, {'word': '笔', 'char_b': 12, 'char_e': 13, 'pos': 'NN'}, {'word': '中', 'char_b': 13, 'char_e': 14, 'pos': 'LC'}, {'word': '哪个', 'char_b': 14, 'char_e': 16, 'pos': 'DT'}, {'word': '笔尖', 'char_b': 16, 'char_e': 18, 'pos': 'NN'}, {'word': '的', 'char_b': 18, 'char_e': 19, 'pos': 'DEG'}, {'word': '硬度', 'char_b': 19, 'char_e': 21, 'pos': 'NN'}, {'word': '高', 'char_b': 21, 'char_e': 22, 'pos': 'VA'}, {'word': '？', 'char_b': 22, 'char_e': 23, 'pos': 'PU'}]}, 'SHINT': [], 'ANSWER': [{'ATEXT': '無法判別', 'ATEXT_CN': '无法判别', 'ATOKEN': [{'text': '無法判別', 'text_cn': '无法判别', 'start': -1, 'end': 3}]}], 'ASPAN': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D288Q12', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '為什麼古埃及人要把死人做成木乃伊?', 'QTEXT_CN': '为什么古埃及人要把死人做成木乃伊?', 'SENTS': [{'text': '为什么古埃及人要把死人做成木乃伊?', 'start': 0, 'end': 17}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '埃及人', 'type': 'NATIONALITY', 'char_b': 4, 'char_e': 7}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '为什么', 'char_b': 0, 'char_e': 3, 'pos': 'AD'}, {'word': '古', 'char_b': 3, 'char_e': 4, 'pos': 'JJ'}, {'word': '埃及人', 'char_b': 4, 'char_e': 7, 'pos': 'NN'}, {'word': '要', 'char_b': 7, 'char_e': 8, 'pos': 'VV'}, {'word': '把', 'char_b': 8, 'char_e': 9, 'pos': 'BA'}, {'word': '死人', 'char_b': 9, 'char_e': 11, 'pos': 'NN'}, {'word': '做成', 'char_b': 11, 'char_e': 13, 'pos': 'VV'}, {'word': '木乃伊', 'char_b': 13, 'char_e': 16, 'pos': 'NN'}, {'word': '?', 'char_b': 16, 'char_e': 17, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D322Q07', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '要如何降低腸病毒的傳播風險？', 'QTEXT_CN': '要如何降低肠病毒的传播风险？', 'SENTS': [{'text': '要如何降低肠病毒的传播风险？', 'start': 0, 'end': 14}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '要', 'char_b': 0, 'char_e': 1, 'pos': 'VV'}, {'word': '如何', 'char_b': 1, 'char_e': 3, 'pos': 'AD'}, {'word': '降低', 'char_b': 3, 'char_e': 5, 'pos': 'VV'}, {'word': '肠', 'char_b': 5, 'char_e': 6, 'pos': 'NN'}, {'word': '病毒', 'char_b': 6, 'char_e': 8, 'pos': 'NN'}, {'word': '的', 'char_b': 8, 'char_e': 9, 'pos': 'DEG'}, {'word': '传播', 'char_b': 9, 'char_e': 11, 'pos': 'NN'}, {'word': '风险', 'char_b': 11, 'char_e': 13, 'pos': 'NN'}, {'word': '？', 'char_b': 13, 'char_e': 14, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "193\n",
      "no gold supporting evidence\n",
      "{'QID': 'D009Q03', 'QTYPE': '申論', 'ATYPE': 'Object', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '「佔領華爾街」運動的訴求為何?', 'QTEXT_CN': '「占领华尔街」运动的诉求为何?', 'SENTS': [{'text': '「占领华尔街」运动的诉求为何?', 'start': 0, 'end': 15}], 'QIE': {'NER': [], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '「', 'char_b': 0, 'char_e': 1, 'pos': 'PU'}, {'word': '占领', 'char_b': 1, 'char_e': 3, 'pos': 'VV'}, {'word': '华尔街', 'char_b': 3, 'char_e': 6, 'pos': 'NR'}, {'word': '」', 'char_b': 6, 'char_e': 7, 'pos': 'PU'}, {'word': '运动', 'char_b': 7, 'char_e': 9, 'pos': 'NN'}, {'word': '的', 'char_b': 9, 'char_e': 10, 'pos': 'DEG'}, {'word': '诉求', 'char_b': 10, 'char_e': 12, 'pos': 'NN'}, {'word': '为何', 'char_b': 12, 'char_e': 14, 'pos': 'AD'}, {'word': '?', 'char_b': 14, 'char_e': 15, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q03', 'QTYPE': '申論', 'ATYPE': 'Organization', 'AMODE': ['Single-Span-Extraction'], 'QTEXT': '世界衛生組織表示有哪些因素造成剛果疫情持續升高?', 'QTEXT_CN': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?', 'SENTS': [{'text': '世界卫生组织表示有哪些因素造成刚果疫情持续升高?', 'start': 0, 'end': 24}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '世界卫生组织', 'type': 'ORG', 'char_b': 0, 'char_e': 6}, {'id': 'D0-S0-M1', 'string': '刚果', 'type': 'COUNTRY', 'char_b': 15, 'char_e': 17}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '世界', 'char_b': 0, 'char_e': 2, 'pos': 'NN'}, {'word': '卫生', 'char_b': 2, 'char_e': 4, 'pos': 'NN'}, {'word': '组织', 'char_b': 4, 'char_e': 6, 'pos': 'NN'}, {'word': '表示', 'char_b': 6, 'char_e': 8, 'pos': 'VV'}, {'word': '有', 'char_b': 8, 'char_e': 9, 'pos': 'VE'}, {'word': '哪些', 'char_b': 9, 'char_e': 11, 'pos': 'DT'}, {'word': '因素', 'char_b': 11, 'char_e': 13, 'pos': 'NN'}, {'word': '造成', 'char_b': 13, 'char_e': 15, 'pos': 'VV'}, {'word': '刚果', 'char_b': 15, 'char_e': 17, 'pos': 'NR'}, {'word': '疫情', 'char_b': 17, 'char_e': 19, 'pos': 'NN'}, {'word': '持续', 'char_b': 19, 'char_e': 21, 'pos': 'VV'}, {'word': '升高', 'char_b': 21, 'char_e': 23, 'pos': 'VV'}, {'word': '?', 'char_b': 23, 'char_e': 24, 'pos': 'PU'}]}, 'SHINT': []}\n",
      "no gold supporting evidence\n",
      "{'QID': 'D321Q04', 'QTYPE': '申論', 'ATYPE': 'Kinship', 'AMODE': ['Kinship'], 'QTEXT': '疾管署民眾應遵守「二不一要」，請問「二不」是什麼?', 'QTEXT_CN': '疾管署民众应遵守「二不一要」，请问「二不」是什么?', 'SENTS': [{'text': '疾管署民众应遵守「二不一要」，', 'start': 0, 'end': 15}, {'text': '请问「二不」是什么?', 'start': 15, 'end': 25}], 'QIE': {'NER': [{'id': 'D0-S0-M0', 'string': '二', 'type': 'NUMBER', 'char_b': 9, 'char_e': 10}, {'id': 'D0-S0-M1', 'string': '一', 'type': 'NUMBER', 'char_b': 11, 'char_e': 12}, {'id': 'D0-S0-M2', 'string': '二', 'type': 'NUMBER', 'char_b': 18, 'char_e': 19}], 'COREF': {}, 'RELATION': [], 'TOKEN': [{'word': '疾管署', 'char_b': 0, 'char_e': 3, 'pos': 'NN'}, {'word': '民众', 'char_b': 3, 'char_e': 5, 'pos': 'NN'}, {'word': '应', 'char_b': 5, 'char_e': 6, 'pos': 'VV'}, {'word': '遵守', 'char_b': 6, 'char_e': 8, 'pos': 'VV'}, {'word': '「', 'char_b': 8, 'char_e': 9, 'pos': 'PU'}, {'word': '二', 'char_b': 9, 'char_e': 10, 'pos': 'CD'}, {'word': '不', 'char_b': 10, 'char_e': 11, 'pos': 'AD'}, {'word': '一', 'char_b': 11, 'char_e': 12, 'pos': 'CD'}, {'word': '要', 'char_b': 12, 'char_e': 13, 'pos': 'VV'}, {'word': '」', 'char_b': 13, 'char_e': 14, 'pos': 'PU'}, {'word': '，', 'char_b': 14, 'char_e': 15, 'pos': 'PU'}, {'word': '请', 'char_b': 15, 'char_e': 16, 'pos': 'VV'}, {'word': '问', 'char_b': 16, 'char_e': 17, 'pos': 'VV'}, {'word': '「', 'char_b': 17, 'char_e': 18, 'pos': 'PU'}, {'word': '二', 'char_b': 18, 'char_e': 19, 'pos': 'CD'}, {'word': '不', 'char_b': 19, 'char_e': 20, 'pos': 'NN'}, {'word': '」', 'char_b': 20, 'char_e': 21, 'pos': 'PU'}, {'word': '是', 'char_b': 21, 'char_e': 22, 'pos': 'VC'}, {'word': '什么', 'char_b': 22, 'char_e': 24, 'pos': 'PN'}, {'word': '?', 'char_b': 24, 'char_e': 25, 'pos': 'PU'}]}, 'SHINT': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2627 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 2627/2627 [22:08<00:00,  1.73it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train_loss: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [03:43<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.08421052631578947, 'sp_prec': 0.40657894736842104, 'sp_recall': 0.24061403508771922, 'sp_f1': 0.2797619047619045}\n",
      "epoch 0 eval_recall: 0.241 eval_f1: 0.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [24:51<00:00,  1.70it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss: 0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:43<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.042105263157894736, 'sp_prec': 0.4241798105575196, 'sp_recall': 0.672293233082707, 'sp_f1': 0.4635268120252641}\n",
      "epoch 1 eval_recall: 0.672 eval_f1: 0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:59<00:00,  2.18it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train_loss: 0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:31<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.05789473684210526, 'sp_prec': 0.26842105263157895, 'sp_recall': 0.13710526315789473, 'sp_f1': 0.16990810359231412}\n",
      "epoch 2 eval_recall: 0.137 eval_f1: 0.170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:57<00:00,  1.86it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train_loss: 0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:57<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.07368421052631578, 'sp_prec': 0.5452255639097745, 'sp_recall': 0.31734335839599004, 'sp_f1': 0.3690601503759396}\n",
      "epoch 3 eval_recall: 0.317 eval_f1: 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:51<00:00,  2.08it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train_loss: 0.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:31<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.1, 'sp_prec': 0.567971370734529, 'sp_recall': 0.5410526315789472, 'sp_f1': 0.5030334577703001}\n",
      "epoch 4 eval_recall: 0.541 eval_f1: 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:43<00:00,  2.27it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train_loss: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:31<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.09473684210526316, 'sp_prec': 0.49242481203007527, 'sp_recall': 0.6195112781954888, 'sp_f1': 0.4962648739380041}\n",
      "epoch 5 eval_recall: 0.620 eval_f1: 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [22:06<00:00,  2.17it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 train_loss: 0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [03:13<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.07894736842105263, 'sp_prec': 0.5589473684210526, 'sp_recall': 0.333734335839599, 'sp_f1': 0.38590225563909775}\n",
      "epoch 6 eval_recall: 0.334 eval_f1: 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:58<00:00,  1.94it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 train_loss: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:31<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.08947368421052632, 'sp_prec': 0.4983334785269772, 'sp_recall': 0.5662406015037598, 'sp_f1': 0.4715581391432786}\n",
      "epoch 7 eval_recall: 0.566 eval_f1: 0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:56<00:00,  1.94it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 train_loss: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:31<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.10526315789473684, 'sp_prec': 0.5523144983671301, 'sp_recall': 0.5950501253132833, 'sp_f1': 0.5196707278563236}\n",
      "epoch 8 eval_recall: 0.595 eval_f1: 0.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [22:05<00:00,  2.06it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 train_loss: 0.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:43<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.10526315789473684, 'sp_prec': 0.6170676691729325, 'sp_recall': 0.42541353383458663, 'sp_f1': 0.46181894129262546}\n",
      "epoch 9 eval_recall: 0.425 eval_f1: 0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:56<00:00,  2.19it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 train_loss: 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [03:11<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.1, 'sp_prec': 0.5678491683754843, 'sp_recall': 0.44437343358396003, 'sp_f1': 0.4544903926482874}\n",
      "epoch 10 eval_recall: 0.444 eval_f1: 0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:52<00:00,  2.28it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 train_loss: 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:30<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.11578947368421053, 'sp_prec': 0.5950793650793651, 'sp_recall': 0.5097243107769426, 'sp_f1': 0.5023662594715229}\n",
      "epoch 11 eval_recall: 0.510 eval_f1: 0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:56<00:00,  2.10it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 train_loss: 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [02:30<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.08947368421052632, 'sp_prec': 0.5490413533834587, 'sp_recall': 0.5239473684210527, 'sp_f1': 0.4851266569687624}\n",
      "epoch 12 eval_recall: 0.524 eval_f1: 0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2627/2627 [21:35<00:00,  2.25it/s]\n",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 train_loss: 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 169/190 [02:29<00:24,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "train_entity_model(20, 12, \"20200302_entity_exp1\")\n",
    "# train_EMSERModel(15, 12, \"20200302_em_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
